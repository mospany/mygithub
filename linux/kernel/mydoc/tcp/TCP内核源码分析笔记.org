#+TITLE: TCP内核源码分析笔记
#+STYLE: <link rel="stylesheet" type="text/css" href="/home/mosp/.emacs.d/style/style.css" />
#+OPTIONS: ^:{} H:5 toc:5 \n:t
#+CATEGORIES: linux内核
#+KEYWORDS: linux, kernel, tcp, 读书笔记， 网络管理
# +html: <div style="height:400px;overflow:auto;border-style:solid;border-width:1px">
# +html: </div>

* 术语
** ABC
   - 英文全称：Appropriate Byte Count
   - 中文全称: 适当字节计数
   - 功能描述: ABC是一种针对于部分确认应答的更慢地增加拥塞窗口(cwnd)的方法。
	 可能的值为：
	 + 0: 每一个应答增加拥塞窗口一次(无ABC)
	 + 1: 每一个最大传输段应答增加拥塞窗口一次
	 + 2：允许增加拥塞控制窗口两次，如果应答是为了补偿延时应答的针对两个段的应答。

** SACK
   - 英文全称: Selective Acknowledgment.
   - 中文全称: 选择性确认
   - 功能描述: SACK是TCP选项，它使得接收方能告诉发送方哪些报文段丢失，哪些报文段重传了，哪些报文段已经提前收到等信息。
     根据这些信息TCP就可以只重传哪些真正丢失的报文段。需要注意的是只有收到失序的分组时才会可能会发送SACK，TCP的ACK还
     是建立在累积确认的基础上的。也就是说如果收到的报文段与期望收到的报文段的序号相同就会发送累积的ACK，SACK只是针对
     失序到达的报文段的。

** D-SACK
   - 英文全称: duplicate-Selective Acknowledgment.
   - 中文全称: 重复的SACK
   - 功能描述: RFC2883中对SACK进行了扩展。SACK中的信息描述的是收到的报文段，这些报文段可能是正常接收的，也可能是重复接收的，
     通过对SACK进行扩展，D-SACK可以在SACK选项中描述它重复收到的报文段。但是需要注意的是D-SACK只用于报告接收端收到的最后一
     个报文与已经接收了的报文的重复部分

** FACK
   - 英文全称: Forward Acknowledgment
   - 中文全称: 提前确认
   - 功能描述: FACK算法采取激进策略，将所有SACK的未确认区间当做丢失段。虽然这种策略通常带来更佳的网络性能，但是过于激进，因为SACK未确认的区间段可能只是发送了重排，而并非丢失

** F-RTO
   - 英文全称: Forward RTO Recovery
   - 中文全称: 虚假超时
   - 功能描述: F-RTO的基本思想是判断RTO是否正常，从而决定是否执行拥塞避免算法。方法是观察RTO之后的两个ACK。如果ACK不是冗余ACK，并且确认的包不是重传
     的，会认为RTO是虚假的就不执行拥塞避免算法。

** nagle算法
   - 功能描述: nagle算法主要目的是减少网络流量，当你发送的数据包太小时，TCP并不立即发送该数据包，而是缓存起来直到数据包到达一定大小后才发送。

** cork算法
   - 功能描述: CORK算法的初衷：提高网络利用率，理想情况下，完全避免发送小包，仅仅发送满包以及不得不发的小包。
	 
	 
** template
   - 英文全称:
   - 中文全称:
   - 功能描述:
	 

* tcp_v4_connect()
  - 描述: 建立与服务器连接，发送SYN段
  - 返回值: 0或错误码
  - 代码关键路径:
 	#+html: <div style="height:400px;overflow:auto;border-style:solid;border-width:1px">
	#+BEGIN_SRC c -n
    int tcp_v4_connect(struct sock *sk, struct sockaddr *uaddr, int addr_len)
    {
        .....　     
     	/* 设置目的地址和目标端口 */
     	inet->dport = usin->sin_port;
     	inet->daddr = daddr;
        ....     
     	/* 初始化MSS上限 */
     	tp->rx_opt.mss_clamp = 536;
     
     	/* Socket identity is still unknown (sport may be zero).
     	 * However we set state to SYN-SENT and not releasing socket
     	 * lock select source port, enter ourselves into the hash tables and
     	 * complete initialization after this.
     	 */
     	tcp_set_state(sk, TCP_SYN_SENT);/* 设置状态 */
     	err = tcp_v4_hash_connect(sk);/* 将传输控制添加到ehash散列表中，并动态分配端口 */
     	if (err)
     		goto failure;
        ....
     	if (!tp->write_seq)/* 还未计算初始序号 */
     		/* 根据双方地址、端口计算初始序号 */
     		tp->write_seq = secure_tcp_sequence_number(inet->saddr,
     							   inet->daddr,
     							   inet->sport,
     							   usin->sin_port);
     
     	/* 根据初始序号和当前时间，随机算一个初始id */
     	inet->id = tp->write_seq ^ jiffies;
     
     	/* 发送SYN段 */
     	err = tcp_connect(sk);
     	rt = NULL;
     	if (err)
     		goto failure;
     
     	return 0;
    }
	#+END_SRC
	#+html: </div>

* sys_accept()
  - 描述: 调用tcp_accept(), 并把它返回的newsk进行连接描述符分配后返回给用户空间。
  - 返回值: 连接描述符
  - 代码关键路径:
	#+html: <div style="height:400px;overflow:auto;border-style:solid;border-width:1px">
	#+BEGIN_SRC c -n
    asmlinkage long sys_accept(int fd, struct sockaddr __user *upeer_sockaddr, int __user *upeer_addrlen)
    {
     	struct socket *sock, *newsock;
        .....     
     	sock = sockfd_lookup(fd, &err);/* 获得侦听端口的socket */
        .....    
     	if (!(newsock = sock_alloc()))/* 分配一个新的套接口，用来处理与客户端的连接 */ 
        .....     
     	/* 调用传输层的accept，对TCP来说，是inet_accept */
     	err = sock->ops->accept(sock, newsock, sock->file->f_flags);
        ....    
     	if (upeer_sockaddr) {/* 调用者需要获取对方套接口地址和端口 */
     		/* 调用传输层回调获得对方的地址和端口 */
     		if(newsock->ops->getname(newsock, (struct sockaddr *)address, &len, 2)<0) {
     		}
     		/* 成功后复制到用户态 */
     		err = move_addr_to_user(address, len, upeer_sockaddr, upeer_addrlen);
     	}
        .....     
     	if ((err = sock_map_fd(newsock)) < 0)/* 为新连接分配文件描述符 */

     	return err;
    }
	#+END_SRC
	#+html: </div>
  
** tcp_accept()
  *[注]*: 在内核2.6.32以后对应函数为inet_csk_accept().
  - 描述: 通过在规定时间内，判断tcp_sock->accept_queue队列非空，代表有新的连接进入．
  - 返回值: (struct sock *)newsk;
  - 代码关键路径:
	#+html: <div style="height:400px;overflow:auto;border-style:solid;border-width:1px">
	#+BEGIN_SRC c -n
    struct sock *tcp_accept(struct sock *sk, int flags, int *err)
    {
        ....
     	/* Find already established connection */
     	if (!tp->accept_queue) {/* accept队列为空，说明还没有收到新连接 */
     		long timeo = sock_rcvtimeo(sk, flags & O_NONBLOCK);/* 如果套口是非阻塞的，或者在一定时间内没有新连接，则返回 */
     
     		if (!timeo)/* 超时时间到，没有新连接，退出 */
     			goto out;
     
     		/* 运行到这里，说明有新连接到来，则等待新的传输控制块 */
     		error = wait_for_connect(sk, timeo);
     		if (error)
     			goto out;
     	}
     
     	req = tp->accept_queue;
     	if ((tp->accept_queue = req->dl_next) == NULL)
     		tp->accept_queue_tail = NULL;
     
     	newsk = req->sk;
     	sk_acceptq_removed(sk);
     	tcp_openreq_fastfree(req);
        ....

       	return newsk;
    }
	#+END_SRC
	#+html: </div>

* 三次握手
** 客户端发送SYN段
   - 由tcp_v4_connect()->tcp_connect()->tcp_transmit_skb()发送，并置为TCP_SYN_SENT.
   - 代码关键路径:
	#+html: <div style="height:400px;overflow:auto;border-style:solid;border-width:1px">
	#+BEGIN_SRC c -n
    /* 构造并发送SYN段 */
    int tcp_connect(struct sock *sk)
    {
     	struct tcp_sock *tp = tcp_sk(sk);
     	struct sk_buff *buff;
     
     	tcp_connect_init(sk);/* 初始化传输控制块中与连接相关的成员 */
     
     	/* 为SYN段分配报文并进行初始化 */
     	buff = alloc_skb(MAX_TCP_HEADER + 15, sk->sk_allocation);
     	if (unlikely(buff == NULL))
     		return -ENOBUFS;
     
     	/* Reserve space for headers. */
     	skb_reserve(buff, MAX_TCP_HEADER);
     
     	TCP_SKB_CB(buff)->flags = TCPCB_FLAG_SYN;
     	TCP_ECN_send_syn(sk, tp, buff);
     	TCP_SKB_CB(buff)->sacked = 0;
     	skb_shinfo(buff)->tso_segs = 1;
     	skb_shinfo(buff)->tso_size = 0;
     	buff->csum = 0;
     	TCP_SKB_CB(buff)->seq = tp->write_seq++;
     	TCP_SKB_CB(buff)->end_seq = tp->write_seq;
     	tp->snd_nxt = tp->write_seq;
     	tp->pushed_seq = tp->write_seq;
     	tcp_ca_init(tp);
     
     	/* Send it off. */
     	TCP_SKB_CB(buff)->when = tcp_time_stamp;
     	tp->retrans_stamp = TCP_SKB_CB(buff)->when;
     
     	/* 将报文添加到发送队列上 */
     	__skb_queue_tail(&sk->sk_write_queue, buff);
     	sk_charge_skb(sk, buff);
     	tp->packets_out += tcp_skb_pcount(buff);
     	/* 发送SYN段 */
     	tcp_transmit_skb(sk, skb_clone(buff, GFP_KERNEL));
     	TCP_INC_STATS(TCP_MIB_ACTIVEOPENS);
     
     	/* Timer for repeating the SYN until an answer. */
     	/* 启动重传定时器 */
     	tcp_reset_xmit_timer(sk, TCP_TIME_RETRANS, tp->rto);
     	return 0;
    }

	#+END_SRC
	#+html: </div>
	 
** 服务端接收到SYN段后，发送SYN/ACK处理
   - 由tcp_v4_do_rcv()->tcp_rcv_state_process()->tcp_v4_conn_request()->tcp_v4_send_synack().
   - tcp_v4_send_synack()
     + tcp_make_synack(sk, dst, req); /* 根据路由、传输控制块、连接请求块中的构建SYN+ACK段 */
	 + ip_build_and_send_pkt(); /* 生成IP数据报并发送出去 */
	#+CAPTION: 图: 服务端接收到SYN段后，发送SYN/ACK处理流程。
    #+BEGIN_SRC dot :file tcp_synack.png :cmdline -Kdot -Tpng
    digraph tcp_synack {
        size = "100, 200";
        fontname = "Microsoft YaHei"
        node [ fontname = "Microsoft YaHei", fontsize = 12, shape = "Mrecord", color="skyblue", style="filled"]; 
        edge [ fontname = "Microsoft YaHei", fontsize = 12, color = "darkgreen" ];
        start [shape = "ellipse", label = "开始"];
//        judge [shape = "diamond", label = "判断"];
        end [shape = "octagon", label = "结束"];

        do_rcv [label = "tcp_v4_do_rcv()"];
        state_process [label = "tcp_rcv_state_process()"];
        conn_request [label = "tcp_v4_conn_request()"];

        subgraph cluster_synack {        
            label="tcp_v4_send_synack";
            color = "dodgerblue";
            bgcolor="lightcyan";

            make_synack [label = "tcp_make_synack()"];
            send_pkt [label = "ip_build_and_send_pkt()"];           
            }

        start -> do_rcv;
        do_rcv -> state_process;
        state_process -> conn_request;

        conn_request -> make_synack;
        make_synack -> send_pkt;
        send_pkt -> end;
    }
    #+END_SRC

   - 代码关键路径:
	#+html: <div style="height:400px;overflow:auto;border-style:solid;border-width:1px">
	#+BEGIN_SRC c -n
    /* 向客户端发送SYN+ACK报文 */
    static int tcp_v4_send_synack(struct sock *sk, struct open_request *req,
     			      struct dst_entry *dst)
    {
     	int err = -1;
     	struct sk_buff * skb;
     
     	/* First, grab a route. */
     	/* 查找到客户端的路由 */
     	if (!dst && (dst = tcp_v4_route_req(sk, req)) == NULL)
     		goto out;
     
     	/* 根据路由、传输控制块、连接请求块中的构建SYN+ACK段 */
     	skb = tcp_make_synack(sk, dst, req);
     
     	if (skb) {/* 生成SYN+ACK段成功 */
     		struct tcphdr *th = skb->h.th;
     
     		/* 生成校验码 */
     		th->check = tcp_v4_check(th, skb->len,
     					 req->af.v4_req.loc_addr,
     					 req->af.v4_req.rmt_addr,
     					 csum_partial((char *)th, skb->len,
     						      skb->csum));
     
     		/* 生成IP数据报并发送出去 */
     		err = ip_build_and_send_pkt(skb, sk, req->af.v4_req.loc_addr,
     					    req->af.v4_req.rmt_addr,
     					    req->af.v4_req.opt);
     		if (err == NET_XMIT_CN)
     			err = 0;
     	}
     
    out:
     	dst_release(dst);
     	return err;
    }
   
   	#+END_SRC
   	#+html: </div>
	   
** 客户端回复确认ACK段
   - 由tcp_v4_do_rcv()->tcp_rcv_state_process().当前客户端处于TCP_SYN_SENT状态。
   - tcp_rcv_synsent_state_process(); /* tcp_rcv_synsent_state_process处理SYN_SENT状态下接收到的TCP段 */
	 + tcp_ack(); /* 处理接收到的ack报文 */
	 + tcp_send_ack(); /* 在主动连接时，向服务器端发送ACK完成连接，并更新窗口 */
	   * alloc_skb(); /* 构造ack段 */
	   * tcp_transmit_skb(); /* 将ack段发出 */
     + tcp_urg(sk, skb, th); /* 处理完第二次握手后，还需要处理带外数据 */
	 + tcp_data_snd_check(sk); /* 检测是否有数据需要发送 */
	   * 检查sk->sk_send_head队列上是否有待发送的数据。
	   * tcp_write_xmit(); /* 将TCP发送队列上的段发送出去 */
  - 代码关键路径:
*** tcp_rcv_synsent_state_process()
	#+html: <div style="height:400px;overflow:auto;border-style:solid;border-width:1px">
	#+BEGIN_SRC c -n
  /* 在SYN_SENT状态下处理接收到的段，但是不处理带外数据 */
  static int tcp_rcv_synsent_state_process(struct sock *sk, struct sk_buff *skb,
   					 struct tcphdr *th, unsigned len)
  {
   	struct tcp_sock *tp = tcp_sk(sk);
   	int saved_clamp = tp->rx_opt.mss_clamp;
   
   	/* 解析TCP选项并保存到传输控制块中 */
   	tcp_parse_options(skb, &tp->rx_opt, 0);
   
   	if (th->ack) {/* 处理ACK标志 */
   		/* rfc793:
   		 * "If the state is SYN-SENT then
   		 *    first check the ACK bit
   		 *      If the ACK bit is set
   		 *	  If SEG.ACK =< ISS, or SEG.ACK > SND.NXT, send
   		 *        a reset (unless the RST bit is set, if so drop
   		 *        the segment and return)"
   		 *
   		 *  We do not send data with SYN, so that RFC-correct
   		 *  test reduces to:
   		 */
   		if (TCP_SKB_CB(skb)->ack_seq != tp->snd_nxt)
   			goto reset_and_undo;
   
   		if (tp->rx_opt.saw_tstamp && tp->rx_opt.rcv_tsecr &&
   		    !between(tp->rx_opt.rcv_tsecr, tp->retrans_stamp,
   			     tcp_time_stamp)) {
   			NET_INC_STATS_BH(LINUX_MIB_PAWSACTIVEREJECTED);
   			goto reset_and_undo;
   		}
   
   		/* Now ACK is acceptable.
   		 *
   		 * "If the RST bit is set
   		 *    If the ACK was acceptable then signal the user "error:
   		 *    connection reset", drop the segment, enter CLOSED state,
   		 *    delete TCB, and return."
   		 */
   
   		if (th->rst) {/* 收到ACK+RST段，需要tcp_reset设置错误码，并关闭套接口 */
   			tcp_reset(sk);
   			goto discard;
   		}
   
   		/* rfc793:
   		 *   "fifth, if neither of the SYN or RST bits is set then
   		 *    drop the segment and return."
   		 *
   		 *    See note below!
   		 *                                        --ANK(990513)
   		 */
   		if (!th->syn)/* 在SYN_SENT状态下接收到的段必须存在SYN标志，否则说明接收到的段无效，丢弃该段 */
   			goto discard_and_undo;
   
   		/* rfc793:
   		 *   "If the SYN bit is on ...
   		 *    are acceptable then ...
   		 *    (our SYN has been ACKed), change the connection
   		 *    state to ESTABLISHED..."
   		 */
   
   		/* 从首部标志中获取显示拥塞通知的特性 */
   		TCP_ECN_rcv_synack(tp, th);
   		if (tp->ecn_flags&TCP_ECN_OK)/* 如果支持ECN，则设置标志 */
   			sk->sk_no_largesend = 1;
   
   		/* 设置与窗口相关的成员变量 */
   		tp->snd_wl1 = TCP_SKB_CB(skb)->seq;
   		tcp_ack(sk, skb, FLAG_SLOWPATH);
   
   		/* Ok.. it's good. Set up sequence numbers and
   		 * move to established.
   		 */
   		tp->rcv_nxt = TCP_SKB_CB(skb)->seq + 1;
   		tp->rcv_wup = TCP_SKB_CB(skb)->seq + 1;
   
   		/* RFC1323: The window in SYN & SYN/ACK segments is
   		 * never scaled.
   		 */
   		tp->snd_wnd = ntohs(th->window);
   		tcp_init_wl(tp, TCP_SKB_CB(skb)->ack_seq, TCP_SKB_CB(skb)->seq);
   
   		if (!tp->rx_opt.wscale_ok) {
   			tp->rx_opt.snd_wscale = tp->rx_opt.rcv_wscale = 0;
   			tp->window_clamp = min(tp->window_clamp, 65535U);
   		}
   
   		if (tp->rx_opt.saw_tstamp) {/* 根据是否支持时间戳选项来设置传输控制块的相关字段 */
   			tp->rx_opt.tstamp_ok	   = 1;
   			tp->tcp_header_len =
   				sizeof(struct tcphdr) + TCPOLEN_TSTAMP_ALIGNED;
   			tp->advmss	    -= TCPOLEN_TSTAMP_ALIGNED;
   			tcp_store_ts_recent(tp);
   		} else {
   			tp->tcp_header_len = sizeof(struct tcphdr);
   		}
   
   		/* 初始化PMTU、MSS等成员变量 */
   		if (tp->rx_opt.sack_ok && sysctl_tcp_fack)
   			tp->rx_opt.sack_ok |= 2;
   
   		tcp_sync_mss(sk, tp->pmtu_cookie);
   		tcp_initialize_rcv_mss(sk);
   
   		/* Remember, tcp_poll() does not lock socket!
   		 * Change state from SYN-SENT only after copied_seq
   		 * is initialized. */
   		tp->copied_seq = tp->rcv_nxt;
   		mb();
   		tcp_set_state(sk, TCP_ESTABLISHED);
   
   		/* Make sure socket is routed, for correct metrics.  */
   		tp->af_specific->rebuild_header(sk);
   
   		tcp_init_metrics(sk);
   
   		/* Prevent spurious tcp_cwnd_restart() on first data
   		 * packet.
   		 */
   		tp->lsndtime = tcp_time_stamp;
   
   		tcp_init_buffer_space(sk);
   
   		/* 如果启用了连接保活，则启用连接保活定时器 */
   		if (sock_flag(sk, SOCK_KEEPOPEN))
   			tcp_reset_keepalive_timer(sk, keepalive_time_when(tp));
   
   		if (!tp->rx_opt.snd_wscale)/* 首部预测 */
   			__tcp_fast_path_on(tp, tp->snd_wnd);
   		else
   			tp->pred_flags = 0;
   
   		if (!sock_flag(sk, SOCK_DEAD)) {/* 如果套口不处于SOCK_DEAD状态，则唤醒等待该套接口的进程 */
   			sk->sk_state_change(sk);
   			sk_wake_async(sk, 0, POLL_OUT);
   		}
   
   		/* 连接建立完成，根据情况进入延时确认模式 */
   		if (sk->sk_write_pending || tp->defer_accept || tp->ack.pingpong) {
   			/* Save one ACK. Data will be ready after
   			 * several ticks, if write_pending is set.
   			 *
   			 * It may be deleted, but with this feature tcpdumps
   			 * look so _wonderfully_ clever, that I was not able
   			 * to stand against the temptation 8)     --ANK
   			 */
   			tcp_schedule_ack(tp);
   			tp->ack.lrcvtime = tcp_time_stamp;
   			tp->ack.ato	 = TCP_ATO_MIN;
   			tcp_incr_quickack(tp);
   			tcp_enter_quickack_mode(tp);
   			tcp_reset_xmit_timer(sk, TCP_TIME_DACK, TCP_DELACK_MAX);
   
  discard:
   			__kfree_skb(skb);
   			return 0;
   		} else {/* 不需要延时确认，立即发送ACK段 */
   			tcp_send_ack(sk);
   		}
   		return -1;
   	}
   
   	/* No ACK in the segment */
   
   	if (th->rst) {/* 收到RST段，则丢弃传输控制块 */
   		/* rfc793:
   		 * "If the RST bit is set
   		 *
   		 *      Otherwise (no ACK) drop the segment and return."
   		 */
   
   		goto discard_and_undo;
   	}
   
   	/* PAWS check. */
   	/* PAWS检测失效，也丢弃传输控制块 */
   	if (tp->rx_opt.ts_recent_stamp && tp->rx_opt.saw_tstamp && tcp_paws_check(&tp->rx_opt, 0))
   		goto discard_and_undo;
   
   	/* 在SYN_SENT状态下收到了SYN段并且没有ACK，说明是两端同时打开 */
   	if (th->syn) {
   		/* We see SYN without ACK. It is attempt of
   		 * simultaneous connect with crossed SYNs.
   		 * Particularly, it can be connect to self.
   		 */
   		tcp_set_state(sk, TCP_SYN_RECV);/* 设置状态为TCP_SYN_RECV */
   
   		if (tp->rx_opt.saw_tstamp) {/* 设置时间戳相关的字段 */
   			tp->rx_opt.tstamp_ok = 1;
   			tcp_store_ts_recent(tp);
   			tp->tcp_header_len =
   				sizeof(struct tcphdr) + TCPOLEN_TSTAMP_ALIGNED;
   		} else {
   			tp->tcp_header_len = sizeof(struct tcphdr);
   		}
   
   		/* 初始化窗口相关的成员变量 */
   		tp->rcv_nxt = TCP_SKB_CB(skb)->seq + 1;
   		tp->rcv_wup = TCP_SKB_CB(skb)->seq + 1;
   
   		/* RFC1323: The window in SYN & SYN/ACK segments is
   		 * never scaled.
   		 */
   		tp->snd_wnd    = ntohs(th->window);
   		tp->snd_wl1    = TCP_SKB_CB(skb)->seq;
   		tp->max_window = tp->snd_wnd;
   
   		TCP_ECN_rcv_syn(tp, th);/* 从首部标志中获取显式拥塞通知的特性。 */
   		if (tp->ecn_flags&TCP_ECN_OK)
   			sk->sk_no_largesend = 1;
   
   		/* 初始化MSS相关的成员变量 */
   		tcp_sync_mss(sk, tp->pmtu_cookie);
   		tcp_initialize_rcv_mss(sk);
   
   		/* 向对端发送SYN+ACK段，并丢弃接收到的SYN段 */
   		tcp_send_synack(sk);
  #if 0
   		/* Note, we could accept data and URG from this segment.
   		 * There are no obstacles to make this.
   		 *
   		 * However, if we ignore data in ACKless segments sometimes,
   		 * we have no reasons to accept it sometimes.
   		 * Also, seems the code doing it in step6 of tcp_rcv_state_process
   		 * is not flawless. So, discard packet for sanity.
   		 * Uncomment this return to process the data.
   		 */
   		return -1;
  #else
   		goto discard;
  #endif
   	}
   	/* "fifth, if neither of the SYN or RST bits is set then
   	 * drop the segment and return."
   	 */
   
  discard_and_undo:
   	tcp_clear_options(&tp->rx_opt);
   	tp->rx_opt.mss_clamp = saved_clamp;
   	goto discard;
   
  reset_and_undo:
   	tcp_clear_options(&tp->rx_opt);
   	tp->rx_opt.mss_clamp = saved_clamp;
   	return 1;
  }

	#+END_SRC
	#+html: </div>
		 
** 服务端收到ACK段
   - 由tcp_v4_do_rcv()->tcp_rcv_state_process().当前服务端处于TCP_SYN_RECV状态变为TCP_ESTABLISHED状态。
  - 代码关键路径:
	#+html: <div style="height:400px;overflow:auto;border-style:solid;border-width:1px">
	#+BEGIN_SRC c -n
/* 除了ESTABLISHED和TIME_WAIT状态外，其他状态下的TCP段处理都由本函数实现 */	
int tcp_rcv_state_process(struct sock *sk, struct sk_buff *skb,
			  struct tcphdr *th, unsigned len)
{
	struct tcp_sock *tp = tcp_sk(sk);
	int queued = 0;

	tp->rx_opt.saw_tstamp = 0;

	switch (sk->sk_state) {
    .....
	/* SYN_RECV状态的处理 */
	if (tcp_fast_parse_options(skb, th, tp) && tp->rx_opt.saw_tstamp &&/* 解析TCP选项，如果首部中存在时间戳选项 */
	    tcp_paws_discard(tp, skb)) {/* PAWS检测失败，则丢弃报文 */
		if (!th->rst) {/* 如果不是RST段 */
			/* 发送DACK给对端，说明接收到的TCP段已经处理过 */
			NET_INC_STATS_BH(LINUX_MIB_PAWSESTABREJECTED);
			tcp_send_dupack(sk, skb);
			goto discard;
		}
		/* Reset is accepted even if it did not pass PAWS. */
	}

	/* step 1: check sequence number */
	if (!tcp_sequence(tp, TCP_SKB_CB(skb)->seq, TCP_SKB_CB(skb)->end_seq)) {/* TCP段序号无效 */
		if (!th->rst)/* 如果TCP段无RST标志，则发送DACK给对方 */
			tcp_send_dupack(sk, skb);
		goto discard;
	}

	/* step 2: check RST bit */
	if(th->rst) {/* 如果有RST标志，则重置连接 */
		tcp_reset(sk);
		goto discard;
	}

	/* 如果有必要，则更新时间戳 */
	tcp_replace_ts_recent(tp, TCP_SKB_CB(skb)->seq);

	/* step 3: check security and precedence [ignored] */

	/*	step 4:
	 *
	 *	Check for a SYN in window.
	 */
	if (th->syn && !before(TCP_SKB_CB(skb)->seq, tp->rcv_nxt)) {/* 如果有SYN标志并且序号在接收窗口内 */
		NET_INC_STATS_BH(LINUX_MIB_TCPABORTONSYN);
		tcp_reset(sk);/* 复位连接 */
		return 1;
	}

	/* step 5: check the ACK field */
	if (th->ack) {/* 如果有ACK标志 */
		/* 检查ACK是否为正常的第三次握手 */
		int acceptable = tcp_ack(sk, skb, FLAG_SLOWPATH);

		switch(sk->sk_state) {
		case TCP_SYN_RECV:
			if (acceptable) {
				tp->copied_seq = tp->rcv_nxt;
				mb();
				/* 正常的第三次握手，设置连接状态为TCP_ESTABLISHED */
				tcp_set_state(sk, TCP_ESTABLISHED);
				sk->sk_state_change(sk);

				/* Note, that this wakeup is only for marginal
				 * crossed SYN case. Passively open sockets
				 * are not waked up, because sk->sk_sleep ==
				 * NULL and sk->sk_socket == NULL.
				 */
				if (sk->sk_socket) {/* 状态已经正常，唤醒那些等待的线程 */
					sk_wake_async(sk,0,POLL_OUT);
				}

				/* 初始化传输控制块，如果存在时间戳选项，同时平滑RTT为0，则需计算重传超时时间 */
				tp->snd_una = TCP_SKB_CB(skb)->ack_seq;
				tp->snd_wnd = ntohs(th->window) <<
					      tp->rx_opt.snd_wscale;
				tcp_init_wl(tp, TCP_SKB_CB(skb)->ack_seq,
					    TCP_SKB_CB(skb)->seq);

				/* tcp_ack considers this ACK as duplicate
				 * and does not calculate rtt.
				 * Fix it at least with timestamps.
				 */
				if (tp->rx_opt.saw_tstamp && tp->rx_opt.rcv_tsecr &&
				    !tp->srtt)
					tcp_ack_saw_tstamp(tp, 0);

				if (tp->rx_opt.tstamp_ok)
					tp->advmss -= TCPOLEN_TSTAMP_ALIGNED;

				/* Make sure socket is routed, for
				 * correct metrics.
				 */
				/* 建立路由，初始化拥塞控制模块 */
				tp->af_specific->rebuild_header(sk);

				tcp_init_metrics(sk);

				/* Prevent spurious tcp_cwnd_restart() on
				 * first data packet.
				 */
				tp->lsndtime = tcp_time_stamp;/* 更新最近一次发送数据包的时间 */

				tcp_initialize_rcv_mss(sk);
				tcp_init_buffer_space(sk);
				tcp_fast_path_on(tp);/* 计算有关TCP首部预测的标志 */
			} else {
				return 1;
			}
			break;
        .....
		}
	} else
		goto discard;
    .....

	/* step 6: check the URG bit */
	tcp_urg(sk, skb, th);/* 检测带外数据位 */

	/* tcp_data could move socket to TIME-WAIT */
	if (sk->sk_state != TCP_CLOSE) {/* 如果tcp_data需要发送数据和ACK则在这里处理 */
		tcp_data_snd_check(sk);
		tcp_ack_snd_check(sk);
	}

	if (!queued) { /* 如果段没有加入队列，或者前面的流程需要释放报文，则释放它 */
discard:
		__kfree_skb(skb);
	}
	return 0;
}
	#+END_SRC
	#+html: </div>

* 数据传输
** 客户端请求数据
   - 由send() -> sendto() -> tcp_sendmsg().当前服务端处于TCP_ESTABLISHED状态。
*** send()
	 send() 直接调用了sendto().
#	#+html: <div style="height:400px;overflow:auto;border-style:solid;border-width:1px">
	#+BEGIN_SRC c -n
    /*
     *	Send a datagram down a socket.
     */
     
    SYSCALL_DEFINE4(send, int, fd, void __user *, buff, size_t, len,
     		unsigned, flags)
    {
     	return sys_sendto(fd, buff, len, flags, NULL, 0);
    }
	#+END_SRC
#	#+html: </div>

	
*** sendto()
	#+html: <div style="height:400px;overflow:auto;border-style:solid;border-width:1px">
	#+BEGIN_SRC c -n
    /*
     *	Send a datagram to a given address. We move the address into kernel
     *	space and check the user space data area is readable before invoking
     *	the protocol.
     */
     
    SYSCALL_DEFINE6(sendto, int, fd, void __user *, buff, size_t, len,
     		unsigned, flags, struct sockaddr __user *, addr,
     		int, addr_len)
    {
     	struct socket *sock;
     	struct sockaddr_storage address;
     	int err;
     	struct msghdr msg;
     	struct iovec iov;
     	int fput_needed;
     
     	if (len > INT_MAX)
     		len = INT_MAX;
     	sock = sockfd_lookup_light(fd, &err, &fput_needed);
     	if (!sock)
     		goto out;

        /* 可以看出用户空间的buff直接赋给了iov.iov_base, iov.iov_len = len */     
     	iov.iov_base = buff;
     	iov.iov_len = len;
     	msg.msg_name = NULL;
     	msg.msg_iov = &iov;
     	msg.msg_iovlen = 1;
     	msg.msg_control = NULL;
     	msg.msg_controllen = 0;
     	msg.msg_namelen = 0;
     	if (addr) {
     		err = move_addr_to_kernel(addr, addr_len, (struct sockaddr *)&address);
     		if (err < 0)
     			goto out_put;
     		msg.msg_name = (struct sockaddr *)&address;
     		msg.msg_namelen = addr_len;
     	}
     	if (sock->file->f_flags & O_NONBLOCK)
     		flags |= MSG_DONTWAIT;
     	msg.msg_flags = flags;
     	err = sock_sendmsg(sock, &msg, len);
     
    out_put:
     	fput_light(sock->file, fput_needed);
    out:
     	return err;
    }
	#+END_SRC
	#+html: </div>

*** __sys_sendmsg()
	关键路径：　
	－ 通过copy_from_user把用户的struct msghdr拷贝到内核的msg_sys。
	－ 也通过verify_iovec()把用户buff中的内容拷贝到内核的iovstack中。
	－ 最后调用sock_sendmsg().
	
	#+html: <div style="height:400px;overflow:auto;border-style:solid;border-width:1px">
	#+BEGIN_SRC c -n
static int __sys_sendmsg(struct socket *sock, struct msghdr __user *msg,
			 struct msghdr *msg_sys, unsigned flags,
			 struct used_address *used_address)
{
	struct compat_msghdr __user *msg_compat =
	    (struct compat_msghdr __user *)msg;
	struct sockaddr_storage address;
	struct iovec iovstack[UIO_FASTIOV], *iov = iovstack;
	unsigned char ctl[sizeof(struct cmsghdr) + 20]
	    __attribute__ ((aligned(sizeof(__kernel_size_t))));
	/* 20 is size of ipv6_pktinfo */
	unsigned char *ctl_buf = ctl;
	int err, ctl_len, iov_size, total_len;

	err = -EFAULT;
	if (MSG_CMSG_COMPAT & flags) {
		if (get_compat_msghdr(msg_sys, msg_compat))
			return -EFAULT;
	}
	else if (copy_from_user(msg_sys, msg, sizeof(struct msghdr)))
		return -EFAULT;

	/* do not move before msg_sys is valid */
	err = -EMSGSIZE;
	if (msg_sys->msg_iovlen > UIO_MAXIOV)
		goto out;

	/* Check whether to allocate the iovec area */
	err = -ENOMEM;
	iov_size = msg_sys->msg_iovlen * sizeof(struct iovec);
	if (msg_sys->msg_iovlen > UIO_FASTIOV) {
		iov = sock_kmalloc(sock->sk, iov_size, GFP_KERNEL);
		if (!iov)
			goto out;
	}

	/* This will also move the address data into kernel space */
	if (MSG_CMSG_COMPAT & flags) {
		err = verify_compat_iovec(msg_sys, iov,
					  (struct sockaddr *)&address,
					  VERIFY_READ);
	} else
		err = verify_iovec(msg_sys, iov,
				   (struct sockaddr *)&address,
				   VERIFY_READ);
	if (err < 0)
		goto out_freeiov;
	total_len = err;

	err = -ENOBUFS;

	if (msg_sys->msg_controllen > INT_MAX)
		goto out_freeiov;
	ctl_len = msg_sys->msg_controllen;
	if ((MSG_CMSG_COMPAT & flags) && ctl_len) {
		err =
		    cmsghdr_from_user_compat_to_kern(msg_sys, sock->sk, ctl,
						     sizeof(ctl));
		if (err)
			goto out_freeiov;
		ctl_buf = msg_sys->msg_control;
		ctl_len = msg_sys->msg_controllen;
	} else if (ctl_len) {
		if (ctl_len > sizeof(ctl)) {
			ctl_buf = sock_kmalloc(sock->sk, ctl_len, GFP_KERNEL);
			if (ctl_buf == NULL)
				goto out_freeiov;
		}
		err = -EFAULT;
		/*
		 * Careful! Before this, msg_sys->msg_control contains a user pointer.
		 * Afterwards, it will be a kernel pointer. Thus the compiler-assisted
		 * checking falls down on this.
		 */
		if (copy_from_user(ctl_buf, (void __user *)msg_sys->msg_control,
				   ctl_len))
			goto out_freectl;
		msg_sys->msg_control = ctl_buf;
	}
	msg_sys->msg_flags = flags;

	if (sock->file->f_flags & O_NONBLOCK)
		msg_sys->msg_flags |= MSG_DONTWAIT;
	/*
	 * If this is sendmmsg() and current destination address is same as
	 * previously succeeded address, omit asking LSM's decision.
	 * used_address->name_len is initialized to UINT_MAX so that the first
	 * destination address never matches.
	 */
	if (used_address && used_address->name_len == msg_sys->msg_namelen &&
	    !memcmp(&used_address->name, msg->msg_name,
		    used_address->name_len)) {
		err = sock_sendmsg_nosec(sock, msg_sys, total_len);
		goto out_freectl;
	}
	err = sock_sendmsg(sock, msg_sys, total_len);
	/*
	 * If this is sendmmsg() and sending to current destination address was
	 * successful, remember it.
	 */
	if (used_address && err >= 0) {
		used_address->name_len = msg_sys->msg_namelen;
		memcpy(&used_address->name, msg->msg_name,
		       used_address->name_len);
	}

out_freectl:
	if (ctl_buf != ctl)
		sock_kfree_s(sock->sk, ctl_buf, ctl_len);
out_freeiov:
	if (iov != iovstack)
		sock_kfree_s(sock->sk, iov, iov_size);
out:
	return err;
}
	
	#+END_SRC
	#+html: </div>
	 
*** tcp_sendmsg():
	#+html: <div style="height:400px;overflow:auto;border-style:solid;border-width:1px">
	#+BEGIN_SRC c -n
/* sendmsg系统调用在TCP层的实现 */
int tcp_sendmsg(struct kiocb *iocb, struct sock *sk, struct msghdr *msg,
		size_t size)
{
	struct iovec *iov;
	struct tcp_sock *tp = tcp_sk(sk);
	struct sk_buff *skb;
	int iovlen, flags;
	int mss_now;
	int err, copied;
	long timeo;

	/* 获取套接口的锁 */
	lock_sock(sk);
	TCP_CHECK_TIMER(sk);

	/* 根据标志计算阻塞超时时间 */
	flags = msg->msg_flags;
	timeo = sock_sndtimeo(sk, flags & MSG_DONTWAIT);

	/* Wait for a connection to finish. */
	if ((1 << sk->sk_state) & ~(TCPF_ESTABLISHED | TCPF_CLOSE_WAIT))/* 只有这两种状态才能发送消息 */
		if ((err = sk_stream_wait_connect(sk, &timeo)) != 0)/* 其它状态下等待连接正确建立，超时则进行错误处理 */
			goto out_err;

	/* This should be in poll */
	clear_bit(SOCK_ASYNC_NOSPACE, &sk->sk_socket->flags);

	/* 获得有效的MSS，如果支持OOB，则不能支持TSO，MSS则应当是比较小的值 */
	mss_now = tcp_current_mss(sk, !(flags&MSG_OOB));

	/* Ok commence sending. */
	/* 获取待发送数据块数及数据块指针 */
	iovlen = msg->msg_iovlen;
	iov = msg->msg_iov;
	/* copied表示从用户数据块复制到skb中的字节数。 */
	copied = 0;

	err = -EPIPE;
	/* 如果套接口存在错误，则不允许发送数据，返回EPIPE错误 */
	if (sk->sk_err || (sk->sk_shutdown & SEND_SHUTDOWN))
		goto do_error;

	while (--iovlen >= 0) {/* 处理所有待发送数据块 */
		int seglen = iov->iov_len;
		unsigned char __user *from = iov->iov_base;

		iov++;

		while (seglen > 0) {/* 处理单个数据块中的所有数据 */
			int copy;

			skb = sk->sk_write_queue.prev;

			if (!sk->sk_send_head ||/* 发送队列为空，前面取得的skb无效 */
			    (copy = mss_now - skb->len) <= 0) {/* 如果skb有效，但是它已经没有多余的空间复制新数据了 */

new_segment:
				/* Allocate new segment. If the interface is SG,
				 * allocate skb fitting to single page.
				 */
				if (!sk_stream_memory_free(sk))/* 发送队列中数据长度达到发送缓冲区的上限，等待缓冲区 */
					goto wait_for_sndbuf;

				skb = sk_stream_alloc_pskb(sk, select_size(sk, tp),
							   0, sk->sk_allocation);/* 分配新的skb */
				if (!skb)/* 分配失败，说明系统内存不足，等待 */
					goto wait_for_memory;

				/*
				 * Check whether we can use HW checksum.
				 */
				if (sk->sk_route_caps &
				    (NETIF_F_IP_CSUM | NETIF_F_NO_CSUM |
				     NETIF_F_HW_CSUM))/* 根据路由网络设备的特性，确定是否由硬件执行校验和 */
					skb->ip_summed = CHECKSUM_HW;

				skb_entail(sk, tp, skb);/* 将SKB添加到发送队列尾部 */
				copy = mss_now;/* 本次需要复制的数据量是MSS */
			}

			/* Try to append data to the end of skb. */
			if (copy > seglen)/* 要复制的数据不能大于当前段的长度 */
				copy = seglen;

			/* Where to copy to? */
			if (skb_tailroom(skb) > 0) {/* skb线性存储区底部还有空间 */
				/* We have some space in skb head. Superb! */
				if (copy > skb_tailroom(skb))/* 本次只复制skb存储区底部剩余空间大小的数据量 */
					copy = skb_tailroom(skb);
				/* 从用户空间复制指定长度的数据到skb中，如果失败，则退出 */
				if ((err = skb_add_data(skb, from, copy)) != 0)
					goto do_fault;
			} else {/* 线性存储区底部已经没有空间了，复制到分散/聚集存储区中 */
				int merge = 0;/* 是否在页中添加数据 */
				int i = skb_shinfo(skb)->nr_frags;/* 分散/聚集片断数 */
				struct page *page = TCP_PAGE(sk);/* 分片页页 */
				int off = TCP_OFF(sk);/* 分片内的偏移 */

				if (skb_can_coalesce(skb, i, page, off) &&
				    off != PAGE_SIZE) {/* 当前分片还能添加数据 */
					/* We can extend the last page
					 * fragment. */
					merge = 1;
				} else if (i == MAX_SKB_FRAGS ||/* 目前skb中的页不能添加数据，这里判断是否能再分配页 */
					   (!i &&
					   !(sk->sk_route_caps & NETIF_F_SG))) {/* 网卡不支持S/G，不能分片 */
					/* Need to add new fragment and cannot
					 * do this because interface is non-SG,
					 * or because all the page slots are
					 * busy. */
					tcp_mark_push(tp, skb);/* SKB可以提交了 */
					goto new_segment;/* 重新分配skb */
				} else if (page) {/* 分页数量未达到上限，判断当前页是否还有空间 */
					/* If page is cached, align
					 * offset to L1 cache boundary
					 */
					off = (off + L1_CACHE_BYTES - 1) &
					      ~(L1_CACHE_BYTES - 1);
					if (off == PAGE_SIZE) {/* 最后一个分页数据已经满，需要分配新页 */
						put_page(page);
						TCP_PAGE(sk) = page = NULL;
					}
				}

				if (!page) {/* 需要分配新页 */
					/* Allocate new cache page. */
					if (!(page = sk_stream_alloc_page(sk)))/* 分配新页，如果内存不足则等待内存 */
						goto wait_for_memory;
					off = 0;
				}

				if (copy > PAGE_SIZE - off)/* 待复制的数据不能大于页中剩余空间 */
					copy = PAGE_SIZE - off;

				/* Time to copy data. We are close to
				 * the end! */
				err = skb_copy_to_page(sk, from, skb, page,
						       off, copy);/* 从用户态复制数据到页中 */
				if (err) {/* 复制失败了 */
					/* If this page was new, give it to the
					 * socket so it does not get leaked.
					 */
					if (!TCP_PAGE(sk)) {/* 如果是新分配的页，则将页记录到skb中，供今后使用 */
						TCP_PAGE(sk) = page;
						TCP_OFF(sk) = 0;
					}
					goto do_error;
				}

				/* Update the skb. */
				/* 更新skb的分段信息 */
				if (merge) {/* 在最后一个页中追加数据 */
					skb_shinfo(skb)->frags[i - 1].size +=
									copy;/* 更新最后一页的数据长度 */
				} else {/* 新分配的页 */
					/* 更新skb中分片信息 */
					skb_fill_page_desc(skb, i, page, off, copy);
					if (TCP_PAGE(sk)) {
						get_page(page);
					} else if (off + copy < PAGE_SIZE) {
						get_page(page);
						TCP_PAGE(sk) = page;
					}
				}

				/* 更新页内偏移 */
				TCP_OFF(sk) = off + copy;
			}

			if (!copied)/* 如果没有复制数据，则取消PSH标志 */
				TCP_SKB_CB(skb)->flags &= ~TCPCB_FLAG_PSH;

			tp->write_seq += copy;/* 更新发送队列最后一个包的序号 */
			TCP_SKB_CB(skb)->end_seq += copy;/* 更新skb的序号 */
			skb_shinfo(skb)->tso_segs = 0;

			/* 更新数据复制的指针 */
			from += copy;
			copied += copy;
			/* 如果所有数据已经复制完毕则退出 */
			if ((seglen -= copy) == 0 && iovlen == 0)
				goto out;

			/* 如果当前skb中的数据小于mss，说明可以往里面继续复制数据。或者发送的是OOB数据，则也跳过发送过程，继续复制数据 */
			if (skb->len != mss_now || (flags & MSG_OOB))
				continue;

			if (forced_push(tp)) {/* 必须立即发送数据，即上次发送后产生的数据已经超过通告窗口值的一半 */
				/* 设置PSH标志后发送数据 */
				tcp_mark_push(tp, skb);
				__tcp_push_pending_frames(sk, tp, mss_now, TCP_NAGLE_PUSH);
			} else if (skb == sk->sk_send_head)/* 虽然不是必须发送数据，但是发送队列上只存在当前段，也将其发送出去 */
				tcp_push_one(sk, mss_now);
			continue;

wait_for_sndbuf:
			/* 由于发送队列满的原因导致等待 */
			set_bit(SOCK_NOSPACE, &sk->sk_socket->flags);
wait_for_memory:
			if (copied)/* 虽然没有内存了，但是本次调用复制了数据到缓冲区，调用tcp_push将其发送出去 */
				tcp_push(sk, tp, flags & ~MSG_MORE, mss_now, TCP_NAGLE_PUSH);

			/* 等待内存可用 */
			if ((err = sk_stream_wait_memory(sk, &timeo)) != 0)
				goto do_error;/* 确实没有内存了，超时后返回失败 */

			/* 睡眠后，MSS可能发生了变化，重新计算 */
			mss_now = tcp_current_mss(sk, !(flags&MSG_OOB));
		}
	}

out:
	if (copied)/* 从用户态复制了数据，发送它 */
		tcp_push(sk, tp, flags, mss_now, tp->nonagle);
	TCP_CHECK_TIMER(sk);
	release_sock(sk);/* 释放锁以后返回 */
	return copied;

do_fault:
	if (!skb->len) {/* 复制数据失败了，如果skb长度为0，说明是新分配的，释放它 */
		if (sk->sk_send_head == skb)/* 如果skb是发送队列头，则清空队列头 */
			sk->sk_send_head = NULL;
		__skb_unlink(skb, skb->list);
		sk_stream_free_skb(sk, skb);/* 释放skb */
	}

do_error:
	if (copied)
		goto out;
out_err:
	err = sk_stream_error(sk, flags, err);
	TCP_CHECK_TIMER(sk);
	release_sock(sk);
	return err;
}
	#+END_SRC
	#+html: </div>

	

** 服务端响应请求
   - 由tcp_v4_do_rcv()->tcp_rcv_established().当前服务端处于TCP_ESTABLISHED状态。
   - 代码关键路径:
	 
* 第25章 传输控制块
** 25.4 传输控制块的内存管理
*** 25.4.4 接收缓存的分配与释放
	书上说到设置该skb的sk宿主时TCP使用sk_stream_set_owner_r(),而到内核kernel-2.6.32中，
	TCP和UDP统一使用skb_set_owner_r().

* 第29章 拥塞控制
** 拥塞状态
 1. TCP_CA_Open 
    这个状态是也就是初始状态，我们可以看到在tcp_create_openreq_child(这个函数的意思可以看我前面的blog)中，
    当我们new一个新的socket之后就会设置这个socket的状态为TCP_CA_Open。这个也可以说是fast path。 

 2. TCP_CA_Disorder 
    当发送者检测到重复的ack或者sack就进入这个状态。在这个状态，拥塞窗口不会被调整，但是这个状态下的话，
    每一次新的输入数据包都会触发一个新的端的传输。 

 3. TCP_CA_CWR 
    这个状态叫做 (Congestion Window Reduced),顾名思义，也就是当拥塞窗口减小的时候会进入这个状态。
    比如当发送者收到一个ECN，此时就需要减小窗口。这个状态能够被Recovery or Loss 所打断。当接收到一个拥塞提醒的时候，
    发送者是每接收到一个ack，就减小拥塞窗口一个段，直到窗口大小减半。因此可以这么说当发送者正在减小窗口并且没有任何重传段的时候，
    就会处于CWR状态。 

 4. TCP_CA_Recovery 
    当足够数量的(一般是3个)的连续的重复ack到达发送端，则发送端立即重传第一个没有被ack的数据段，然后进入这个状态。
    处于这个状态的时候，发送者也是和CWR状态类似，每次接收到ack后减小窗口。在这个状态，拥塞窗口不会增长，发送者要么重传标记lost的段，
    要么传输新的段。当发送者进入这个状态时的没有被ack的段全部ack之后就离开这个状态。 

 5. TCP_CA_Loss 
    当RTO超时后，发送者就进入这个状态。此时所有的没有被ack的段都标记为loss，然后降低窗口大小为1,然后进入慢开始阶段。
    loss状态不能被其他状态所中断。而这个状态的退出只有当进入loss时，所有的被标记为loss的段都得到ack后，才会再次返回open状态。
** cwnd初始值
   - 客户端初始化是在发送syn包后接收到syn/ack包时处于SYN_SENT状态下进行初始化的。
	 tcp_rcv_synsent_state_process[5472] tcp_init_metrics(sk);
   - 服务端初始化是在接收到syn包处于SYN_RECV状态下初始化的。
　　　tcp_rcv_state_process[5713]    tcp_init_metrics(sk);　　
   - tcp_init_metrics()调用tcp_init_cwnd().
     tp->snd_cwnd = tcp_init_cwnd(tp, dst);
   - tcp_init_cwnd()里实现取路由里设置的cwnd，TCP_INIT_CWND与tp->snd_cwnd_clamp取最小值。
	 	#+BEGIN_SRC c -n
       __u32 tcp_init_cwnd(struct tcp_sock *tp, struct dst_entry *dst)
       {
        	__u32 cwnd = (dst ? dst_metric(dst, RTAX_INITCWND) : 0);
        
        	if (!cwnd)
        		cwnd = TCP_INIT_CWND;
        	return min_t(__u32, cwnd, tp->snd_cwnd_clamp);
       }
	 	#+END_SRC
	 [注]: 目前centos 6.2里kernel-2.6.32的TCP_INIT_CWND值为10.
     -------------------------------------------------------------------------------
     *** include/net/tcp.h:
     TCP_INIT_CWND[203]             #define TCP_INIT_CWND 10
     -------------------------------------------------------------------------------
	 + tp->snd_cwnd_clamp为允许的最大拥塞窗口值，初始值为65535。
	   它通过tcp_v4_init_sock()里调用:
	   	tp->snd_cwnd_clamp = ~0;
	   实现，其类型为u16.

   -------------------------------------------------------------------------------
   *** net/ipv4/tcp_input.c:
   tcp_rcv_synsent_state_process[5472] tcp_init_metrics(sk);
   tcp_rcv_state_process[5713]    tcp_init_metrics(sk);
   -------------------------------------------------------------------------------
   
** SACK/RENO/FACK是否启用
 	#+BEGIN_SRC c -n   
  /* These function determine how the currrent flow behaves in respect of SACK 
   * handling. SACK is negotiated with the peer, and therefore it can very between 
   * different flows. 
   * 
   * tcp_is_sack - SACK enabled 
   * tcp_is_reno - No SACK 
   * tcp_is_fack - FACK enabled, implies SACK enabled 
   */  
  static inline int tcp_is_sack (const struct tcp_sock *tp)  
  {  
          return tp->rx_opt.sack_ok; /* SACK seen on SYN packet */  
  }

  /* Look for tcp options. Normally only called on SYN and SYNACK packets.
   * But, this can also be called on packets in the established flow when
   * the fast version below fails.
   */
  void tcp_parse_options(struct sk_buff *skb, struct tcp_options_received *opt_rx,
   		       int estab)
  {
    ............  
   	case TCPOPT_SACK_PERM:
   		if (opsize == TCPOLEN_SACK_PERM && th->syn &&
   		    !estab && sysctl_tcp_sack) {
   			opt_rx->sack_ok = 1; /* 从syn包的选项中协商与sysctl_tcp_sack配置 */
   			tcp_sack_reset(opt_rx);
   		}
   		break;
    ............
  }
   #+END_SRC

   #+BEGIN_SRC c -n      
  static inline int tcp_is_reno (const struct tcp_sock *tp)  
  {  
          return ! tcp_is_sack(tp);  /* 不是sack就是newReno */
  }  
   #+END_SRC
   #+BEGIN_SRC c -n      
  static inline int tcp_is_fack (const struct tcp_sock *tp)  
  {  
          return tp->rx_opt.sack_ok & 2;  
  }

  /* 客户端使能fack. */
  static int tcp_rcv_synsent_state_process(struct sock *sk, struct sk_buff *skb,
   					 struct tcphdr *th, unsigned len)
  {
  ......
   	if (tcp_is_sack(tp) && sysctl_tcp_fack)
   		tcp_enable_fack(tp);
  ......
  }
   
  /* 服务端使能fack. */
  /* This is not only more efficient than what we used to do, it eliminates
   * a lot of code duplication between IPv4/IPv6 SYN recv processing. -DaveM
   *
   * Actually, we could lots of memory writes here. tp of listening
   * socket contains all necessary default parameters.
   */
  struct sock *tcp_create_openreq_child(struct sock *sk, struct request_sock *req, struct sk_buff *skb)
  {
  ......
   	if ((newtp->rx_opt.sack_ok = ireq->sack_ok) != 0) {
   		if (sysctl_tcp_fack)
   			tcp_enable_fack(newtp);
   	}
  ......
  }
   #+END_SRC

   #+BEGIN_SRC c -n      
  static inline void tcp_enable_fack(struct tcp_sock *tp)  
  {  
          tp->rx_opt.sack_ok |= 2;  
  }  
   #+END_SRC
   #+BEGIN_SRC c -n      
  static inline int tcp_fackets_out(const struct tcp_sock *tp)  
  {  
          return tcp_is_reno(tp) ? tp->sacked_out +1 : tp->fackets_out;  
  }  
   #+END_SRC
  （1）如果启用了FACK，那么fackets_out = left_out
             fackets_out = sacked_out + loss_out
             所以：loss_out = fackets_out - sacked_out
            这是一种比较激进的丢包估算，即FACK。
  （2）如果没启用FACK，那么就假设只丢了一个数据包，所以left_out = sacked_out + 1
          这是一种较为保守的做法，当出现大量丢包时，这种做法会出现问题。    
   
   
** 慢启动
*** 连接建立时
    在建立连接时，做为服务器端会通过tcp_v4_do_rcv（）－－》tcp_v4_hnd_req（）－－》tcp_che 
    ck_req（）－－－》inet_csk(sk)->icsk_af_ops->syn_recv_sock（） 
    ，即tcp_v4_syn_recv_sock（）－－》tcp_create_openreq_child（）来将新的连接设为TCP_CA_Open状态。
	 	#+BEGIN_SRC c -n	
        struct sock *tcp_create_openreq_child(）
        ｛
                struct sock *newsk = inet_csk_clone(sk, req, GFP_ATOMIC);
         
         	if (newsk != NULL) {
         	.....
         		tcp_set_ca_state(newsk, TCP_CA_Open);
            .....
                ｝
         
        }

	 	#+END_SRC

    至于客户端，没有发现显式的设置TCP_CA_Open状态的语句，但TCP_CA_Open等于0，在创建SOCK结 
    故,就被全初始化为0了，所以在建好连接时，客户端也应该是TCP_CA_Open状态。 	
	
*** tcp_ack()
	这个函数主要功能是： 
	1 update重传队列，并基于sack来设置skb的相关buf。 
	2 update发送窗口。 
	3 基于sack的信息或者重复ack来决定是否进入拥塞模式。
*** 拥塞控制入口
    每接收到一个传输数据包的响应ack包进入tcp_cong_avoid()中判读该进行慢启动还是拥塞避免处理流程。
	 	#+BEGIN_SRC c -n
       static int tcp_ack(struct sock *sk, struct sk_buff *skb, int flag)
       {
        	if (tcp_ack_is_dubious(sk, flag)) {
        		/* Advance CWND, if state allows this. */
        		if ((flag & FLAG_DATA_ACKED) && !frto_cwnd &&
        		    tcp_may_raise_cwnd(sk, flag))
        			tcp_cong_avoid(sk, ack, prior_in_flight);
        		tcp_fastretrans_alert(sk, prior_packets - tp->packets_out,
        				      flag);
        	} else {
        		if ((flag & FLAG_DATA_ACKED) && !frto_cwnd)
        			tcp_cong_avoid(sk, ack, prior_in_flight);
        	}
       }
	 	#+END_SRC

*** snd_ssthresh设置
    这个值在加载cubic模块的时候可以传递一个我们制定的值给它，不过，默认是很大的值，我这里是2147483647,然后在接收ack期间(slow start)期间会调整这个值，
	在cubic中，默认是16（一般来说说当拥塞窗口到达16的时候，snd_ssthresh会被设置为16).
    在cubic中有两个可以设置snd_ssthresh的地方一个是hystart_update，一个是bictcp_recalc_ssthresh，后一个我这里就不介绍了，以后介绍拥塞状态机的时候
	会详细介绍，现在只需要知道，只有遇到拥塞的时候，需要调整snd_ssthres的时候，我们才需要调用bictcp_recalc_ssthresh。
    而hystart_update是在bictcp_acked中被调用，而bictcp_acked则是基本每次收到ack都会调用这个函数，我们来看在bictcp_acked中什么情况就会调用
	hystart_update：
	调用关系: tcp_ack() --> tcp_clean_rtx_queue() --> ca_ops->pkts_acked() --> bictcp_acked().
 	#+BEGIN_SRC c -n	
    /* hystart triggers when cwnd is larger than some threshold */
    if (hystart && tp->snd_cwnd <= tp->snd_ssthresh &&
        tp->snd_cwnd >= hystart_low_window)
        hystart_update(sk, delay);
 	#+END_SRC	
    其中hystart是hybrid slow start打开的标志，默认是开启，hystart_low_window是设置snd_ssthresh的最小拥塞窗口值，默认是16。而tp->snd_ssthresh默认
	是一个很大的值，因此这里就知道了，当拥塞窗口增大到16的时候我们就会进去hystart_update来更新snd_ssthresh.因此hystart_updat换句话来说也就是主要用于
	是否退出slow start。
 	#+BEGIN_SRC c -n
    static int hystart_low_window __read_mostly = 16;
    module_param(hystart_low_window, int, 0644);
    MODULE_PARM_DESC(hystart_low_window, "lower bound cwnd for hybrid slow start");

    static void hystart_update(struct sock *sk, u32 delay)
    {
        struct tcp_sock *tp = tcp_sk(sk);
        struct bictcp *ca = inet_csk_ca(sk);
     
        if (!(ca->found & hystart_detect)) {
    .................................................................
            /*
             * Either one of two conditions are met,
             * we exit from slow start immediately.
             */
    //found是一个是否退出slow start的标记
            if (ca->found & hystart_detect)
    //设置snd_ssthresh
                tp->snd_ssthresh = tp->snd_cwnd;
        }
    }
 	#+END_SRC	
	
    然后是slow start的处理,这里有关abc的处理，注释都很详细了，这里就不解释了，我们主要看abc关闭的部分。这里使用cnt，也是主要为了打开abc之后的slow start。
    这是abc（Appropriate Byte Counting）相关的rfc：

*** snd_cwnd_clamp设置
    关于snd_cwnd_clamp变量，在《linux内核源码剖析——TCP/IP实现（下册）》p717，讲到：snd_cwnd_clamp是允许的拥塞窗口最大值，初始值为65535，之后再接收SYN和ACK段时，
	会根据条件确定是否从路由配置项读取信息更新该字段，最后在TCP连接复位前，将更新后的值根据某种算法计算后再更新回相对应的路由配置项中，便于连接使用。
**** 初始值后第一次修改
	 啥时候第一次修改的路由配置项还不清楚。

**** 连接复位前更新
	- 客户端
	  + 调用关系： tcp_time_wait() --> tcp_update_metrics().
        -------------------------------------------------------------------------------
        *** net/ipv4/tcp.c:
        tcp_close[1972]                tcp_time_wait(sk, TCP_FIN_WAIT2, tmo);
         
        *** net/ipv4/tcp_input.c:
        tcp_fin[4030]                  tcp_time_wait(sk, TCP_TIME_WAIT, 0);
        tcp_rcv_state_process[5763]    tcp_time_wait(sk, TCP_FIN_WAIT2, tmo);
        tcp_rcv_state_process[5772]    tcp_time_wait(sk, TCP_TIME_WAIT, 0);
         
        *** net/ipv4/tcp_timer.c:
        tcp_keepalive_timer[504]       tcp_time_wait(sk, TCP_FIN_WAIT2, tmo);
        -------------------------------------------------------------------------------
	  + 更新时机：  
      *** net/ipv4/tcp_minisocks.c:
      tcp_time_wait[357]             tcp_update_metrics(sk);
	- 服务端
	  + 调用关系： tcp_ack() ->  tcp_rcv_state_process() --> tcp_update_metrics();
	  + 更新时机：
      *** net/ipv4/tcp_input.c:
      tcp_rcv_state_process[5779]    tcp_update_metrics(sk);
	  
	#+html: <div style="height:400px;overflow:auto;border-style:solid;border-width:1px">
	#+BEGIN_SRC c -n
    void tcp_update_metrics(struct sock *sk)
    {
    ......
     		if (tcp_in_initial_slowstart(tp)) {
     			/* Slow start still did not finish. */
     			if (dst_metric(dst, RTAX_SSTHRESH) &&
     			    !dst_metric_locked(dst, RTAX_SSTHRESH) &&
     			    (tp->snd_cwnd >> 1) > dst_metric(dst, RTAX_SSTHRESH))
     				dst->metrics[RTAX_SSTHRESH-1] = tp->snd_cwnd >> 1;
     			if (!dst_metric_locked(dst, RTAX_CWND) &&
     			    tp->snd_cwnd > dst_metric(dst, RTAX_CWND))
     				dst->metrics[RTAX_CWND - 1] = tp->snd_cwnd;
     		} else if (tp->snd_cwnd > tp->snd_ssthresh &&
     			   icsk->icsk_ca_state == TCP_CA_Open) {
     			/* Cong. avoidance phase, cwnd is reliable. */
     			if (!dst_metric_locked(dst, RTAX_SSTHRESH))
     				dst->metrics[RTAX_SSTHRESH-1] =
     					max(tp->snd_cwnd >> 1, tp->snd_ssthresh);
     			if (!dst_metric_locked(dst, RTAX_CWND))
     				dst->metrics[RTAX_CWND-1] = (dst_metric(dst, RTAX_CWND) + tp->snd_cwnd) >> 1;
     		} else {
     			/* Else slow start did not finish, cwnd is non-sense,
     			   ssthresh may be also invalid.
     			 */
     			if (!dst_metric_locked(dst, RTAX_CWND))
     				dst->metrics[RTAX_CWND-1] = (dst_metric(dst, RTAX_CWND) + tp->snd_ssthresh) >> 1;
     			if (dst_metric(dst, RTAX_SSTHRESH) &&
     			    !dst_metric_locked(dst, RTAX_SSTHRESH) &&
     			    tp->snd_ssthresh > dst_metric(dst, RTAX_SSTHRESH))
     				dst->metrics[RTAX_SSTHRESH-1] = tp->snd_ssthresh;
     		}
    ......		
    }		
   	#+END_SRC
	#+html: </div>
     
	
*** 拥塞控制实现
	 	#+BEGIN_SRC c -n
        static void bictcp_cong_avoid(struct sock *sk, u32 ack, u32 in_flight)
        {
            struct tcp_sock *tp = tcp_sk(sk);
            struct bictcp *ca = inet_csk_ca(sk);
            //判断发送拥塞窗口是否到达限制，如果到达限制则直接返回。
            if (!tcp_is_cwnd_limited(sk, in_flight))
                return;
            //开始决定进入slow start还是拥塞控制状态
            if (tp->snd_cwnd <= tp->snd_ssthresh) {
                //是否需要reset对应的bictcp的值
                if (hystart && after(ack, ca->end_seq))
                    bictcp_hystart_reset(sk);
                //进入slow start状态
                tcp_slow_start(tp);
            } else {
                //进入拥塞避免状态，首先会更新ca->cnt.
                bictcp_update(ca, tp->snd_cwnd);
                //然后进入拥塞避免
                tcp_cong_avoid_ai(tp, ca->cnt);
            }
        }
	 	#+END_SRC

*** 慢启动算法
	#+html: <div style="height:400px;overflow:auto;border-style:solid;border-width:1px">
	#+BEGIN_SRC c -n
    void tcp_slow_start(struct tcp_sock *tp)
    {
        int cnt; /* increase in packets */
     
        /* RFC3465: ABC Slow start
         * Increase only after a full MSS of bytes is acked
         *
         * TCP sender SHOULD increase cwnd by the number of
         * previously unacknowledged bytes ACKed by each incoming
         * acknowledgment, provided the increase is not more than L
         */
        if (sysctl_tcp_abc && tp->bytes_acked < tp->mss_cache)
            return;
    //限制slow start的cnt
        if (sysctl_tcp_max_ssthresh > 0 && tp->snd_cwnd > sysctl_tcp_max_ssthresh)
            cnt = sysctl_tcp_max_ssthresh >> 1;   /* limited slow start */
        else
            cnt = tp->snd_cwnd;          /* exponential increase */
     
        /* RFC3465: ABC
         * We MAY increase by 2 if discovered delayed ack
         */
        if (sysctl_tcp_abc > 1 && tp->bytes_acked >= 2*tp->mss_cache)
            cnt <<= 1;
        tp->bytes_acked = 0;
    //更新cnt，也就是当前拥塞窗口接受的段的个数.
        tp->snd_cwnd_cnt += cnt;
        while (tp->snd_cwnd_cnt >= tp->snd_cwnd) {
    //这里snd_cwnd_cnt是snd_cwnd的几倍，拥塞窗口就增加几。
            tp->snd_cwnd_cnt -= tp->snd_cwnd;
    //如果拥塞窗口没有超过最大值，则加一
            if (tp->snd_cwnd < tp->snd_cwnd_clamp)
                tp->snd_cwnd++;
        }
    }
   	#+END_SRC
	#+html: </div>

*** 备注
    这里着重解释一下，cwnd的指数增长是如何进行的，所有的文献中都会提到，cwnd在一个RTT内会翻倍，这里看到的源码似乎不是这样，而是接收一个ACK就加一。
	这里疑惑了一下，接收一个ACK的时间不就是RTT吗？其实不是的，一个cwnd内的包是一起发送的，之间相关的时间很短，只和带宽有关，ACK也是连续返回的，
	一个cwnd内的所有ACK都返回了才算是一个RTT。每返回一个ACK，cwnd就加一，那等所有ACK都返回了，cwnd也就翻倍了。

** 拥塞避免
*** 拥塞避免算法
	通过判断当前的拥塞窗口下已经发送的数据段的个数是否大于算法计算出来的值w，如果大于我们才能增加拥塞窗口值，否则之需要增加snd_cwnd_cnt。
	#+BEGIN_SRC c -n
    void tcp_cong_avoid_ai(struct tcp_sock *tp, u32 w)
    {
    //判断是否大于我们的标记值
        if (tp->snd_cwnd_cnt >= w) {
            if (tp->snd_cwnd < tp->snd_cwnd_clamp)
                tp->snd_cwnd++;
            tp->snd_cwnd_cnt = 0;
        } else {
    //增加计数值
            tp->snd_cwnd_cnt++;
    }    
   	#+END_SRC

** 快速重传
   快速重传：tcp_ack中的丢包检测，即检测到连续3个重复ACK。
   超时重传是TCP协议保证数据可靠性的一个重要机制，其原理是在发送一个数据以后就开启一个计时器，
   在一定时间内如果没有得到发送数据报的ACK报文，那么就重新发送数据，直到发送成功为止。这是数据
   包丢失的情况下给出的一种修补机制。一般来说，重传发生在超时之后，但是如果发送端接收到3个以上
   的重复ACK，就应该意识到，数据丢了，需要重新传递。这个机制不需要等到重传定时器溢出，所以叫
   做快速重传，而快速重传以后，因为走的不是慢启动而是拥塞避免算法，所以这又叫做快速恢复算法。
   快速重传和快速恢复旨在：快速恢复丢失的数据包。
   没有快速重传和快速恢复，TCP将会使用定时器来要求传输暂停。在暂停这段时间内，没有新的数据包
   被发送。
*** 快速重传做的事情有：
   1. 把ssthresh设置为cwnd的一半
   2. 把cwnd再设置为ssthresh的值(具体实现有些为ssthresh+3)
   3. 重新进入拥塞避免阶段。
*** 第一个重复的ACK
	现在的TCP协议中默认都是支持SACK,FACK,D-SACK的 。用sysctl -a|grep ack 就可知道。 
    但具体到一个连接的支持情况还要看三次握手，只要双方都支持了SACK，FACK就会自动打开，只有有一方不支持SACK，连接就处于最基本的reno方法的拥塞控制。 
    FACK和SACK都是很好的东西，是对传统的RENO的改进，具体请看相应的RFC等。 
    下面试图分析一下《TCP／IP详解》的第21章的图21-7的情况下内核的实现，基于2.6.21。为了简化分析，现在只假设连接只支持RENO，以后会对FACK，SACK，D－SACK进行分析。
	抓包发现搜狐的服务器现在竟然不支持SACK！！
	假设已经在传输过程中，如图所示，第45个包丢失了。 
	下面分析第60个包的运行情况，只对slip端进行分析，下同：
	#+html: <div style="height:400px;overflow:auto;border-style:solid;border-width:1px">
	#+BEGIN_SRC c -n
    static int tcp_ack(struct sock *sk, struct sk_buff *skb, int flag)
    {
     	 ......
     	u32 prior_snd_una = tp->snd_una;  
     	u32 ack_seq = TCP_SKB_CB(skb)->seq;
     	u32 ack = TCP_SKB_CB(skb)->ack_seq;
             ....
     	if (!(flag&FLAG_SLOWPATH) && after(ack, prior_snd_una)) { // <1>
     	 ....
     	} else {
     		if (ack_seq != TCP_SKB_CB(skb)->end_seq)
     			flag |= FLAG_DATA;
     		else
     			NET_INC_STATS_BH(LINUX_MIB_TCPPUREACKS);
     
     		flag |= tcp_ack_update_window(sk, tp, skb, ack, ack_seq); //<2>
     		if (TCP_SKB_CB(skb)->sacked)                              //<3>
     			flag |= tcp_sacktag_write_queue(sk, skb, prior_snd_una);
     		if (TCP_ECN_rcv_ecn_echo(tp, skb->h.th))
     			flag |= FLAG_ECE;
     
     		tcp_ca_event(sk, CA_EVENT_SLOW_ACK);
     	}
    ｝	
	#+END_SRC
	#+html: </div>
	
	作为60这个包，这个tcp_ack()是通过tcp_rcv_established()的FAST 
    PATH进去的，flag的值是0，ack的值是等于prior_snd_una，<1>处的判断使代码运行到< 
    2>处，因为不支持SACK，所以<3>处不会进入，下面说一下<2>:
	
	#+html: <div style="height:400px;overflow:auto;border-style:solid;border-width:1px">
	#+BEGIN_SRC c -n
    static int tcp_ack_update_window(struct sock *sk, struct tcp_sock *tp,
     				 struct sk_buff *skb, u32 ack, u32 ack_seq)
    {
     	int flag = 0;
     	u32 nwin = ntohs(skb->h.th->window);
     
     	if (likely(!skb->h.th->syn))
     		nwin <<= tp->rx_opt.snd_wscale;
     
     	if (tcp_may_update_window(tp, ack, ack_seq, nwin)) {  //<4>
     		flag |= FLAG_WIN_UPDATE;                      //<5>
     	............
     	}
     	tp->snd_una = ack;
     	return flag;
    }
     
     static inline int tcp_may_update_window(const struct tcp_sock *tp, const u32 ack,
     					const u32 ack_seq, const u32 nwin)
    {
     	return (after(ack, tp->snd_una) ||
     		after(ack_seq, tp->snd_wl1) ||
     		(ack_seq == tp->snd_wl1 && nwin > tp->snd_wnd));   //<6>
    }
	#+END_SRC
	#+html: </div>
     
    <4>处是不会进入的除非，新的窗口比原来的大 
    ,见<6>，所以<5>处不会被运行，FLAG_WIN_UPDATE不会被置。

   为了方便分析，假设新窗口不增大，FLAG_WIN_UPDATE不会被置。 
   回到tcp_ack().
	#+html: <div style="height:400px;overflow:auto;border-style:solid;border-width:1px">
	#+BEGIN_SRC c -n
   static int tcp_ack(struct sock *sk, struct sk_buff *skb, int flag)
   {
   ........................
    	flag |= tcp_clean_rtx_queue(sk, &seq_rtt);   //<7>
    	if (tp->frto_counter)
    		tcp_process_frto(sk, prior_snd_una);
    	if (tcp_ack_is_dubious(sk, flag)) {    //<8>
    		/* Advance CWND, if state allows this. */
    		if ((flag & FLAG_DATA_ACKED) && tcp_may_raise_cwnd(sk, flag))//<9>
    			tcp_cong_avoid(sk, ack,  seq_rtt, prior_in_flight, 0);
    		tcp_fastretrans_alert(sk, prior_snd_una, prior_packets, flag);  //<10>
    	} else {
    		if ((flag & FLAG_DATA_ACKED))
    			tcp_cong_avoid(sk, ack, seq_rtt, prior_in_flight, 1);
    	}
   .......................
   }
	#+END_SRC
	#+html: </div>

   注意 tcp_ack_update_window（）中的 “tp->snd_una = ack”， 
   <7>处是根据这种更新后进行的计算。 
   tcp_clean_rtx_queue（）主要是对来的ACK进行检查，看是否可以把已ACK的数据从发送队列 
   sk_write_queue中去掉，并返回FLAG_DATA_ACKED标志。 
   本情况下,不会任何操作就返回了，因为还不能从sk_write_queue中拿掉任何数据。 
    
   根据目前的flag的情况，<8>处是肯定会进入的,具体请自行分析， 
   <9>处flag不满足FLAG_DATA_ACKED，最后进入<10>。 
	#+BEGIN_SRC c -n
   #define FLAG_ACKED		(FLAG_DATA_ACKED|FLAG_SYN_ACKED)
   #define FLAG_NOT_DUP		(FLAG_DATA|FLAG_WIN_UPDATE|FLAG_ACKED)
   #define FLAG_CA_ALERT		(FLAG_DATA_SACKED|FLAG_ECE)
   static inline int tcp_ack_is_dubious(const struct sock *sk, const int flag)
   {
    	return (!(flag & FLAG_NOT_DUP) || (flag & FLAG_CA_ALERT) ||
    		inet_csk(sk)->icsk_ca_state != TCP_CA_Open);
   }
	#+END_SRC

	#+html: <div style="height:400px;overflow:auto;border-style:solid;border-width:1px">
	#+BEGIN_SRC c -n
    static void tcp_fastretrans_alert( )
    {
    ...............
     	 int is_dupack = (tp->snd_una == prior_snd_una &&
    !(flag&FLAG_NOT_DUP)); //<11>
    .................................
          /* F. Process state. */
     	switch (icsk->icsk_ca_state) {
     	case TCP_CA_Recovery:
     	..................
     		break;
     	case TCP_CA_Loss:
     	..............................
     	default:
     		if (IsReno(tp)) {                   //<12>
     			if (tp->snd_una != prior_snd_una)
     				tcp_reset_reno_sack(tp);
     			if (is_dupack)
     				tcp_add_reno_sack(sk);   //<13>
     		}
     ..............................................
     		if (!tcp_time_to_recover(sk, tp)) {  //<14>
     			tcp_try_to_open(sk, tp, flag); //<15>
     			return;   //<16>
     		}
    ....................
    }
	#+END_SRC
	#+html: </div>
     
    因为是RENO，所以进入<12>处。is_dupack为1，在<13>处tcp_add_reno_sack（）增� 
    觮p->sacked_out. 
    <14>的tcp_time_to_recover（）是个极为重要的函数，对第一个重复的ACK而言，返回的是0。 
    在<15>处的tcp_try_to_open会将icsk->icsk_ca_state的状态由原来的TCP_CA_Open设为 
    TCP_CA_Disorder。 
    <16>处返回整个函数。这2个函数后面会介绍，现在只是提其功能。

*** 第2个重复的ACK
   在不增加窗口大小的情况下，本ACK包还是会通过FASTPATH进入tcp_ack()函数。在增加了sacked_out后与第一个重复的ACK一样就返回了。 

*** 第3个重复的ACK
   该ACK包与前2个包不同之处是：这个包要更新拥塞控制的状态了，这个就是经典的RENO：3个重复ACK引发重传。
	#+html: <div style="height:400px;overflow:auto;border-style:solid;border-width:1px">
	#+BEGIN_SRC c -n
   static int tcp_time_to_recover(struct sock *sk, struct tcp_sock *tp)
   {
    	__u32 packets_out;
    
    	/* Trick#1: The loss is proven. */
    	if (tp->lost_out)
    		return 1;
    
    	/* Not-A-Trick#2 : Classic rule... */
     	// if (tcp_dupack_heuristics(tp) > tp->reordering) // 在linux kernel-2.6.32已经改成行了，
        // static inline int tcp_dupack_heuristics(struct tcp_sock *tp)
        // {
        //  	return tcp_is_fack(tp) ? tp->fackets_out : tp->sacked_out + 1;
        // }
    	if (tcp_fackets_out(tp) > tp->reordering)   //<17> 
    		return 1;
    
    	/* Trick#3 : when we use RFC2988 timer restart, fast
    	 * retransmit can be triggered by timeout of queue head.
    	 */
    	if (tcp_head_timedout(sk, tp))
    		return 1;
    
    	/* Trick#4: It is still not OK... But will it be useful to delay
    	 * recovery more?
    	 */
    	packets_out = tp->packets_out;
    	if (packets_out <= tp->reordering &&
    	    tp->sacked_out >= max_t(__u32, packets_out/2, sysctl_tcp_reordering)
   && !tcp_may_send_now(sk, tp)) {
    		/* We have nothing to send. This connection is limited
    		 * either by receiver window or by application.
    		 */
    		return 1;
    	}
    
    	return 0;
   }
	#+END_SRC
	#+html: </div>
    
   <17>处的tp->reordering初始化的值是3，这个就是个乱序包的阈值。因为没有SACK，FA 
   CK，所以tcp_fackets_out(tp)其实就是返回 sacked_out+1，也就是4，呵呵，终于可以返回1了。 
   ------------------------------------------------------------------------------
   ** include/net/tcp.h:
   CP_FASTRETRANS_THRESH[75]     #define TCP_FASTRETRANS_THRESH 3
   ------------------------------------------------------------------------------
   ./tcp_input.c:79:int sysctl_tcp_reordering __read_mostly = TCP_FASTRETRANS_THRESH;
   ./tcp_ipv4.c:1824:	tp->reordering = sysctl_tcp_reordering;

   第3个重复的ACK在tcp_time_to_recover（）返回1后，会在
	#+html: <div style="height:400px;overflow:auto;border-style:solid;border-width:1px">
	#+BEGIN_SRC c -n
   tcp_fastretrans_alert()
   {
    	switch (icsk->icsk_ca_state) {
   ..............................
    		tp->high_seq = tp->snd_nxt;    //<18>
    		tp->prior_ssthresh = 0;
    		tp->undo_marker = tp->snd_una;
    		tp->undo_retrans = tp->retrans_out;
    
    	 	if (icsk->icsk_ca_state < TCP_CA_CWR) {
    			if (!(flag&FLAG_ECE))
    				tp->prior_ssthresh = tcp_current_ssthresh(sk);
    			tp->snd_ssthresh = icsk->icsk_ca_ops->ssthresh(sk);  // <19>
    			TCP_ECN_queue_cwr(tp);
    		}
    		tp->bytes_acked = 0;
    		tp->snd_cwnd_cnt = 0;
    		tcp_set_ca_state(sk, TCP_CA_Recovery); // <20> 
    	}
    
    	if (is_dupack || tcp_head_timedout(sk, tp))
    		tcp_update_scoreboard(sk, tp);   //<21>
    	tcp_cwnd_down(sk);             //<22>
    	tcp_xmit_retransmit_queue(sk);  //<23>
   }
	#+END_SRC
	#+html: </div>
    
   <18> : 此处设置发生状态转化时的最高发送序号 tp->snd_nxt，以后会用到它。 
   <19> : 最终调用RENO的tcp_reno_ssthresh（）进行经典运算，将snd_ssthresh设为tp->snd_cwnd的一半。
	#+BEGIN_SRC c -n
    /* Slow start threshold is half the congestion window (min 2) */
    u32 tcp_reno_ssthresh(struct sock *sk)
    {
     	const struct tcp_sock *tp = tcp_sk(sk);
     	return max(tp->snd_cwnd >> 1U, 2U);
    }
    EXPORT_SYMBOL_GPL(tcp_reno_ssthresh);
	#+END_SRC
   <20> : 将本连接从TCP_CA_Disorder变为TCP_CA_Recovery。 
   <21> : 主要是把 要重发的那个包的进行：TCP_SKB_CB(skb)->sacked |= TCPCB_LOST。增加tp->lost_out的值， 
   还有一些帮助用的hint变量。 
   <22> : tcp_cwnd_down()每收到2个ACK，就把发送控制窗口tp->snd_cwnd缩小。
	#+html: <div style="height:400px;overflow:auto;border-style:solid;border-width:1px">
	#+BEGIN_SRC c -n
        /* Decrease cwnd each second ack. */
        static void tcp_cwnd_down(struct sock *sk, int flag)
        {
         	struct tcp_sock *tp = tcp_sk(sk);
         	int decr = tp->snd_cwnd_cnt + 1;
         
         	if ((flag & (FLAG_ANY_PROGRESS | FLAG_DSACKING_ACK)) ||
         	    (tcp_is_reno(tp) && !(flag & FLAG_NOT_DUP))) {
         		tp->snd_cwnd_cnt = decr & 1;
         		decr >>= 1;
         
         		if (decr && tp->snd_cwnd > tcp_cwnd_min(sk))
         			tp->snd_cwnd -= decr;
         
         		tp->snd_cwnd = min(tp->snd_cwnd, tcp_packets_in_flight(tp) + 1);
         		tp->snd_cwnd_stamp = tcp_time_stamp;
         	}
        }
	#+END_SRC
	#+html: </div>
   <23> : 因为<20>已经把要重发的包标为TCPCB_LOST，在这里会引起重发这个包，同时重置RTO时钟 
   （此场景中的3个重复的ACK是不会是RTO超时的，一般的RTO大约几秒，而这3个ACK才1秒多,我也确 
   实没有找到重置RTO的地方）
   
** 快速恢复
   后来的“快速恢复”算法是在上述的“快速重传”算法后添加的，当收到3个重复ACK时，TCP最后进入的不是拥塞避免阶段，而是快速恢复阶段。
   快速重传和快速恢复算法一般同时使用。快速恢复的思想是“数据包守恒”原则，即同一个时刻在网络中的数据包数量是恒定的，只有当“老”数
   据包离开了网络后，才能向网络中发送一个“新”的数据包，如果发送方收到一个重复的ACK，那么根据TCP的ACK机制就表明有一个数据包离开
   了网络，于是cwnd加1。如果能够严格按照该原则那么网络中很少会发生拥塞，事实上拥塞控制的目的也就在修正违反该原则的地方。
*** 具体来说快速恢复的主要步骤是：
   1. 当收到3个重复ACK时，把ssthresh设置为cwnd的一半，把cwnd设置为ssthresh的值加3，然后重传丢失的报文段，加3的原因是因为
	  收到3个重复的ACK，表明有3个“老”的数据包离开了网络。 
   2. 再收到重复的ACK时，拥塞窗口增加1。
   3. 当收到新的数据包的ACK时，把cwnd设置为第一步中的ssthresh的值。原因是因为该ACK确认了新的数据，说明从重复ACK时的数据都已收到，
	  该恢复过程已经结束，可以回到恢复之前的状态了，也即再次进入拥塞避免状态。
	  Reno在收到一个新的数据的ACK时就退出了快速恢复状态了，而NewReno需要收到该窗口内所有数据包的确认后才会退出快速恢复状态，
	  从而更一步提高吞吐量。
   快速恢复：bictcp_undo_cwnd，直接把snd_cwnd更新为max(snd_cwnd，last_max_cwnd)，和掉包前相差不大。

** 拥塞状态机
　拥塞状态机处理最主要的函数就是tcp_fastretrans_alert，进入这个函数的条件:
　- each incoming ACK, if state is not “Open”(每个处于非OPEN状态的ack包)
  - when arrived ACK is unusual, namely: (异常的ack包类型如下)
    + SACK
    + Duplicate ACK.
    + ECN ECE.
  在tcp_ack()中调用的，进入这个函数就意味着我们碰到了拥塞状态或者在拥塞状态处理tcp。在这个函数中，实现了下面的这些算法： 
  1 失败重传。 
  2 从不同的拥塞状态恢复。 
  3 检测到一个失败的拥塞状态从而使数据包的传输的延迟。 
  4 从所有的拥塞状态恢复到Open状态。
　此函数分成几个阶段：
　A. FLAG_ECE，收到包含ECE标志的ACK。
　B. reneging SACKs，ACK指向已经被SACK的数据段。如果是此原因，进入超时处理，然后返回。
　C. state is not Open，发现丢包，需要标志出丢失的包，这样就知道该重传哪些包了。
　D. 检查是否有错误( left_out > packets_out)。
　E. 各个状态是怎样退出的，当snd_una >= high_seq时候。
　F. 各个状态的处理和进入。  
 	#+html: <div style="height:400px;overflow:auto;border-style:solid;border-width:1px">
	#+BEGIN_SRC c -n
    struct inet_connection_sock *icsk = inet_csk(sk);  
        struct tcp_sock *tp = tcp_sk(sk);  
    ///FLAG_SND_UNA_ADVANCED表示Snd_una被改变，也就是当前的ack不是一个重复ack。而FLAG_NOT_DUP表示也表示不是重复ack。  
        int is_dupack = !(flag & (FLAG_SND_UNA_ADVANCED | FLAG_NOT_DUP));  
    //判断是否有丢失的段。  
        int do_lost = is_dupack || ((flag & FLAG_DATA_SACKED) &&  
                        (tcp_fackets_out(tp) > tp->reordering));  
        int fast_rexmit = 0, mib_idx;  
      
     //如果发送未确认的数据包为0，则我们必须要重置sacked_out.  
         if (WARN_ON(!tp->packets_out && tp->sacked_out))  
             tp->sacked_out = 0;  
     //如果sacked_out为0，则fackets_out也必须设置为0.这是因为fack的计数依赖于最少一个sack的段。  
         if (WARN_ON(!tp->sacked_out && tp->fackets_out))  
             tp->fackets_out = 0;  
       
         /* Now state machine starts. 
          * A. ECE, hence prohibit cwnd undoing, the reduction is required. */  
     ///如果接收到ece则reset慢开始的界限。这是因为我们就要开始减小窗口了，所以这样就能停止慢开始。  
         if (flag & FLAG_ECE)  
             tp->prior_ssthresh = 0;  
       
         /* B. In all the states check for reneging SACKs. */  
     //这个主要用来判断当前的ack是不是确认的是已经被sack的数据段，如果是的话，说明对端有bug或者不能正确的处理OFO的数据段。此时我们需要destroy掉所有的sack信息，然后返回。  
         if (tcp_check_sack_reneging(sk, flag))  
             return;  
       
         /* C. Process data loss notification, provided it is valid. */  
       
     //这段主要是为了判断数据是否丢失。前两个判断主要是flag和fack的判定。  
         if (tcp_is_fack(tp) && (flag & FLAG_DATA_LOST) &&  
     //这个为真说明一些段可能已经被接受端sack掉了。  
             before(tp->snd_una, tp->high_seq) &&  
     //这个说明当前已经进入了拥塞处理的状态。  
             icsk->icsk_ca_state != TCP_CA_Open &&  
     //这个为真说明在重传队列开始的一些段已经丢失。  
             tp->fackets_out > tp->reordering) {  
     ///到达这里，我们将会依次标记所有的重传段都为丢失，直到我们发现第一个被sacked的段。  
             tcp_mark_head_lost(sk, tp->fackets_out - tp->reordering);  
             NET_INC_STATS_BH(sock_net(sk), LINUX_MIB_TCPLOSS);  
         }  
        /* D. Check consistency of the current state. */  
        tcp_verify_left_out(tp);  
	#+END_SRC
	#+html: </div>
    接下来就看这几个状态是如何变迁的，因此我这里只是用来描述状态变迁相关的函数。
    首先状态变迁分为两部分，一部分是进入某些状态，一部分是从某些状态跳出来。首先来分析状态的默认处理，也就是假设是处于Open状态，然后收到了异常的ACK,此时代码是如何处理的.。
    这里要注意TCP reno算法是用快重传来模拟SACK，所以如果关闭了SACK那么就需要模拟SACK.
 	#+html: <div style="height:400px;overflow:auto;border-style:solid;border-width:1px">
	#+BEGIN_SRC c -n 
        switch (icsk->icsk_ca_state) {
    ...........................................................................................
            /* Loss is undone; fall through to processing in Open state. */
    // 进入下面则有可能是　disorder,open, cwr,loss 这几个状态.
        default:
    //如果SACK关闭，那么就需要模拟SACK
            if (tcp_is_reno(tp)) {
                if (flag & FLAG_SND_UNA_ADVANCED)
                    tcp_reset_reno_sack(tp);
                if (is_dupack)
                    tcp_add_reno_sack(sk);
            }
    //从DSACK恢复
            if (icsk->icsk_ca_state <= TCP_CA_Disorder)
                tcp_try_undo_dsack(sk);
    //是否需要进入revocer状态。
            if (!tcp_time_to_recover(sk, flag)) {
    //如果不需要，则尝试着检测是否需要进入CWR或者Disorder状态.
                tcp_try_to_open(sk, flag);
                return;
            }
     
            /* MTU probe failure: don't reduce cwnd */
            if (icsk->icsk_ca_state < TCP_CA_CWR &&
                icsk->icsk_mtup.probe_size &&
                tp->snd_una == tp->mtu_probe.probe_seq_start) {
                tcp_mtup_probe_failed(sk);
                /* Restores the reduction we did in tcp_mtup_probe() */
                tp->snd_cwnd++;
                tcp_simple_retransmit(sk);
                return;
            }
    //最终进入recovery状态
            /* Otherwise enter Recovery state */
            tcp_enter_recovery(sk, (flag & FLAG_ECE));
            fast_rexmit = 1;
        }
	#+END_SRC
	#+html: </div>

      上面有三个函数需要详细分析，分别是tcp_time_to_recover,tcp_try_to_open以及tcp_enter_recovery。
      首先是tcp_time_to_recover,这个函数主要是用来判断是否需要进入recover状态。
       
      首先来描述下几个基本概念，一个就是重定序长度(reordering),这个值的意思是当有大于１个的SACK之后，相差最大的两个SACK之间的距离,
      比如第一个SACK通知的序列是7,第二个是2，那么reordering值就是6.而FACK_OUT表示sack确认的最大的序列号。
 	#+html: <div style="height:400px;overflow:auto;border-style:solid;border-width:1px">
	#+BEGIN_SRC c -n   
      static bool tcp_time_to_recover(struct sock *sk, int flag)
      {
          struct tcp_sock *tp = tcp_sk(sk);
          __u32 packets_out;
       
          /* Do not perform any recovery during F-RTO algorithm */
          if (tp->frto_counter)
              return false;
       
          /* Trick#1: The loss is proven. */
          if (tp->lost_out)
              return true;
       
          /* Not-A-Trick#2 : Classic rule... */
      //如果SACK的最大序列号大于重定序长度，那么说明重定序序列中头部的数据一定丢失，那么就需要进入recover状态.
          if (tcp_dupack_heuristics(tp) > tp->reordering)
              return true;
       
          /* Trick#3 : when we use RFC2988 timer restart, fast
           * retransmit can be triggered by timeout of queue head.
           */
      //如果数据包超时(因为每次重传定时器都会被重置),则进入recover状态.
          if (tcp_is_fack(tp) && tcp_head_timedout(sk))
              return true;
       
          /* Trick#4: It is still not OK... But will it be useful to delay
           * recovery more?
           */
          packets_out = tp->packets_out;
      //这里不太理解什么意思
          if (packets_out <= tp->reordering &&
              tp->sacked_out >= max_t(__u32, packets_out/2, sysctl_tcp_reordering) &&
              !tcp_may_send_now(sk)) {
              /* We have nothing to send. This connection is limited
               * either by receiver window or by application.
               */
              return true;
          }
       
          /* If a thin stream is detected, retransmit after first
           * received dupack. Employ only if SACK is supported in order
           * to avoid possible corner-case series of spurious retransmissions
           * Use only if there are no unsent data.
           */
      //处理thin stream
          if ((tp->thin_dupack || sysctl_tcp_thin_dupack) &&
              tcp_stream_is_thin(tp) && tcp_dupack_heuristics(tp) > 1 &&
              tcp_is_sack(tp) && !tcp_send_head(sk))
              return true;
       
          /* Trick#6: TCP early retransmit, per RFC5827.  To avoid spurious
           * retransmissions due to small network reorderings, we implement
           * Mitigation A.3 in the RFC and delay the retransmission for a short
           * interval if appropriate.
           */
      //处理early retransmit
          if (tp->do_early_retrans && !tp->retrans_out && tp->sacked_out &&
              (tp->packets_out == (tp->sacked_out + 1) && tp->packets_out < 4) &&
              !tcp_may_send_now(sk))
              return !tcp_pause_early_retransmit(sk, flag);
       
      //最终返回false.
          return false;
      }
	#+END_SRC
	#+html: </div>
      然后来看tcp_try_to_open方法,这个函数名字有点问题，它的主要作用是检测是否需要进入CWR或者Disorder状态.
 	#+html: <div style="height:400px;overflow:auto;border-style:solid;border-width:1px">
	#+BEGIN_SRC c -n 
      static void tcp_try_to_open(struct sock *sk, int flag)
      {
          struct tcp_sock *tp = tcp_sk(sk);
       
          tcp_verify_left_out(tp);
       
          if (!tp->frto_counter && !tcp_any_retrans_done(sk))
              tp->retrans_stamp = 0;
      //如果接受到ECE那么就进入cwr状态.
          if (flag & FLAG_ECE)
              tcp_enter_cwr(sk, 1);
       
          if (inet_csk(sk)->icsk_ca_state != TCP_CA_CWR) {
      //检测是否需要进入disorder状态，否则进入open状态.
              tcp_try_keep_open(sk);
      //如果不是open状态，则修改拥塞窗口
              if (inet_csk(sk)->icsk_ca_state != TCP_CA_Open)
                  tcp_moderate_cwnd(tp);
          } else {
      //减小拥塞窗口
              tcp_cwnd_down(sk, flag);
          }
      }
	#+END_SRC
	#+html: </div>
	  
      然后来看tcp__try_keep_open方法，这个方法就是判断是否进入Disorder状态.条件很简单，那就是要么有SACK的段或者有丢失的段，要么有任何重传的段，
      那么就进入Disorder状态。
	#+BEGIN_SRC c -n 
      static void tcp_try_keep_open(struct sock *sk)
      {
          struct tcp_sock *tp = tcp_sk(sk);
      //默认是进入open状态
          int state = TCP_CA_Open;
      //进入Disorder状态
          if (tcp_left_out(tp) || tcp_any_retrans_done(sk))
              state = TCP_CA_Disorder;
       
          if (inet_csk(sk)->icsk_ca_state != state) {
              tcp_set_ca_state(sk, state);
              tp->high_seq = tp->snd_nxt;
          }
      }
	#+END_SRC
      然后就是tcp_enter_recovery，这个函数主要就是用来进入recover状态，然后设置相关的域。
      high_seq : 进入recover状态时的snd_nxt.
      undo_marker: 表示进入revover状态时的snd_una
      undo_retrans: 表示进入revover状态时的重传段个数
 	#+html: <div style="height:400px;overflow:auto;border-style:solid;border-width:1px">
	#+BEGIN_SRC c -n 
      static void tcp_enter_recovery(struct sock *sk, bool ece_ack)
      {
          struct tcp_sock *tp = tcp_sk(sk);
          int mib_idx;
       
          if (tcp_is_reno(tp))
              mib_idx = LINUX_MIB_TCPRENORECOVERY;
          else
              mib_idx = LINUX_MIB_TCPSACKRECOVERY;
       
          NET_INC_STATS_BH(sock_net(sk), mib_idx);
      //更新相关域
          tp->high_seq = tp->snd_nxt;
          tp->prior_ssthresh = 0;
          tp->undo_marker = tp->snd_una;
          tp->undo_retrans = tp->retrans_out;
       
          if (inet_csk(sk)->icsk_ca_state < TCP_CA_CWR) {
              if (!ece_ack)
      //保存当前的ssthresh,以便于后续恢复
                  tp->prior_ssthresh = tcp_current_ssthresh(sk);
      //更新slow start的阈值.
              tp->snd_ssthresh = inet_csk(sk)->icsk_ca_ops->ssthresh(sk);
              TCP_ECN_queue_cwr(tp);
          }
       
          tp->bytes_acked = 0;
          tp->snd_cwnd_cnt = 0;
      //保存拥塞窗口
          tp->prior_cwnd = tp->snd_cwnd;
          tp->prr_delivered = 0;
          tp->prr_out = 0;
      //进入recovery状态
          tcp_set_ca_state(sk, TCP_CA_Recovery);
      }
	#+END_SRC
	#+html: </div>

      然后来看tcp_enter_cwr，这个函数主要是用于进入CWR状态。看这个函数的时候，可以看到和上面recover状态使用的变量的设置关系.
 	#+html: <div style="height:400px;overflow:auto;border-style:solid;border-width:1px">
	#+BEGIN_SRC c -n 
      void tcp_enter_cwr(struct sock *sk, const int set_ssthresh)
      {
          struct tcp_sock *tp = tcp_sk(sk);
          const struct inet_connection_sock *icsk = inet_csk(sk);
       
          tp->prior_ssthresh = 0;
          tp->bytes_acked = 0;
          if (icsk->icsk_ca_state < TCP_CA_CWR) {
              tp->undo_marker = 0;
              if (set_ssthresh)
                  tp->snd_ssthresh = icsk->icsk_ca_ops->ssthresh(sk);
              tp->snd_cwnd = min(tp->snd_cwnd,
                         tcp_packets_in_flight(tp) + 1U);
              tp->snd_cwnd_cnt = 0;
      //设置最大序列号
              tp->high_seq = tp->snd_nxt;
              tp->snd_cwnd_stamp = tcp_time_stamp;
              TCP_ECN_queue_cwr(tp);
      //进入CWR状态.
              tcp_set_ca_state(sk, TCP_CA_CWR);
          }
      }
	#+END_SRC
	#+html: </div>
	  
      可以看到上面的设置保存了很多值，那么这些值在什么时候使用呢，先来看上面的代码分析中跳过的片段,也就是tcp_try_undo_dsack函数。
       
      这个函数主要是用于检测是否需要从cwnd减小的驱使中恢复，这里判断条件就是undo_marker和undo_retrans.
      这里undo_retrans为0,则表示没有重传任何数据，或者说重传的数据都已经被DSACK了，从而说明数据都已经安全抵达，那么这个时候自然需要从cwr恢复。
	#+BEGIN_SRC c -n
      static void tcp_try_undo_dsack(struct sock *sk)
      {
          struct tcp_sock *tp = tcp_sk(sk);
       
          if (tp->undo_marker && !tp->undo_retrans) {
              DBGUNDO(sk, "D-SACK");
      //恢复拥塞窗口以及slow start的阈值。
              tcp_undo_cwr(sk, true);
              tp->undo_marker = 0;
              NET_INC_STATS_BH(sock_net(sk), LINUX_MIB_TCPDSACKUNDO);
          }
      }
	#+END_SRC
	  
      从上面可以看到核心就是tcp_undo_cwr函数。这个函数主要就是用于重置发送拥塞窗口和slow start的阈值.
 	#+html: <div style="height:400px;overflow:auto;border-style:solid;border-width:1px">
	#+BEGIN_SRC c -n 
      static void tcp_undo_cwr(struct sock *sk, const bool undo_ssthresh)
      {
          struct tcp_sock *tp = tcp_sk(sk);
       
          if (tp->prior_ssthresh) {
              const struct inet_connection_sock *icsk = inet_csk(sk);
       
              if (icsk->icsk_ca_ops->undo_cwnd)
                  tp->snd_cwnd = icsk->icsk_ca_ops->undo_cwnd(sk);
              else
                  tp->snd_cwnd = max(tp->snd_cwnd, tp->snd_ssthresh << 1);
       
              if (undo_ssthresh && tp->prior_ssthresh > tp->snd_ssthresh) {
      //恢复到先前保存的阈值
                  tp->snd_ssthresh = tp->prior_ssthresh;
                  TCP_ECN_withdraw_cwr(tp);
              }
          } else {
              tp->snd_cwnd = max(tp->snd_cwnd, tp->snd_ssthresh);
          }
          tp->snd_cwnd_stamp = tcp_time_stamp;
      }
	#+END_SRC
	#+html: </div>

      然后来看在recover状态下，如何处理重复/部分确认.
	#+BEGIN_SRC c -n 
          case TCP_CA_Recovery:
      //如果收到了重复确认
              if (!(flag & FLAG_SND_UNA_ADVANCED)) {
      //如果是reno算法，则更新sack
                  if (tcp_is_reno(tp) && is_dupack)
                      tcp_add_reno_sack(sk);
              } else
      //接收到了部分确认，那么此时就需要撤销先前的设置
                  do_lost = tcp_try_undo_partial(sk, pkts_acked);
              break;
	#+END_SRC
			  
      然后来看tcp_try_undo_partial,这个函数就是用来检查是否可以从接受到的部分确认撤销，它的返回值就是是否需要标记一些段为丢失。
       
      这里要注意tcp_may_undo函数，这个函数主要用于判断是否是错误的进入了拥塞状态，如果是那么就返回true，然后接下来就需要从错误的状态撤销.
      它的判断类似上面的tcp_try_undo_dsack。
 	#+html: <div style="height:400px;overflow:auto;border-style:solid;border-width:1px">
	#+BEGIN_SRC c -n 
      static int tcp_try_undo_partial(struct sock *sk, int acked)
      {
          struct tcp_sock *tp = tcp_sk(sk);
          /* Partial ACK arrived. Force Hoe's retransmit. */
          int failed = tcp_is_reno(tp) || (tcp_fackets_out(tp) > tp->reordering);
      //判断是否需要撤销
          if (tcp_may_undo(tp)) {
              /* Plain luck! Hole if filled with delayed
               * packet, rather than with a retransmit.
               */
              if (!tcp_any_retrans_done(sk))
                  tp->retrans_stamp = 0;
      //update重定序长度
              tcp_update_reordering(sk, tcp_fackets_out(tp) + acked, 1);
       
              DBGUNDO(sk, "Hoe");
      //从cwr撤销
              tcp_undo_cwr(sk, false);
              NET_INC_STATS_BH(sock_net(sk), LINUX_MIB_TCPPARTIALUNDO);
       
              /* So... Do not make Hoe's retransmit yet.
               * If the first packet was delayed, the rest
               * ones are most probably delayed as well.
               */
              failed = 0;
          }
          return failed;
      }
	#+END_SRC
	#+html: </div>
	  
      然后就是LOSS状态的处理，也就是说在LOSS状态时处理重复以及部分确认.这个状态的处理类似上面的recover状态，因此这里就简要的描述下.
	#+BEGIN_SRC c -n 
          case TCP_CA_Loss:
              if (flag & FLAG_DATA_ACKED)
                  icsk->icsk_retransmits = 0;
              if (tcp_is_reno(tp) && flag & FLAG_SND_UNA_ADVANCED)
                  tcp_reset_reno_sack(tp);
      //判断是否需要从LOSS状态撤销
              if (!tcp_try_undo_loss(sk)) {
      //不需要撤销，则调整拥塞窗口
                  tcp_moderate_cwnd(tp);
      //重传
                  tcp_xmit_retransmit_queue(sk);
                  return;
              }
              if (icsk->icsk_ca_state != TCP_CA_Open)
                  return;
	#+END_SRC

      最后我们来看退出拥塞状态检测的处理，也就是当发送未确认的段大于等于high_seq(拥塞发生时的snd_nxt).当大于high_seq的时候，则说明可能我们需要从拥塞状态退出了，
      因为此时可能当拥塞状态发生时丢失的段都已经传输完毕。
 	#+html: <div style="height:400px;overflow:auto;border-style:solid;border-width:1px">
	#+BEGIN_SRC c -n 
              case TCP_CA_Loss:
                  icsk->icsk_retransmits = 0;
      //尝试撤销拥塞状态
                  if (tcp_try_undo_recovery(sk))
                      return;
                  break;
       
              case TCP_CA_CWR:
                  /* CWR is to be held something *above* high_seq
                   * is ACKed for CWR bit to reach receiver. */
                  if (tp->snd_una != tp->high_seq) {
                      tcp_complete_cwr(sk);
      //恢复到open状态.
                      tcp_set_ca_state(sk, TCP_CA_Open);
                  }
                  break;
       
              case TCP_CA_Recovery:
                  if (tcp_is_reno(tp))
                      tcp_reset_reno_sack(tp);
      //尝试撤销拥塞状态
                  if (tcp_try_undo_recovery(sk))
                      return;
      //完成cwr
                  tcp_complete_cwr(sk);
                  break;
              }
	#+END_SRC
	#+html: </div>
			  
      来看最后一个函数，也就是tcp_try_undo_recovery函数。这个函数主要就是用于撤销拥塞状态。
 	#+html: <div style="height:400px;overflow:auto;border-style:solid;border-width:1px">
	#+BEGIN_SRC c -n 
      static bool tcp_try_undo_recovery(struct sock *sk)
      {
          struct tcp_sock *tp = tcp_sk(sk);
      //是否需要撤销
          if (tcp_may_undo(tp)) {
              int mib_idx;
       
              /* Happy end! We did not retransmit anything
               * or our original transmission succeeded.
               */
              DBGUNDO(sk, inet_csk(sk)->icsk_ca_state == TCP_CA_Loss ? "loss" : "retrans");
      //撤销设置
              tcp_undo_cwr(sk, true);
              if (inet_csk(sk)->icsk_ca_state == TCP_CA_Loss)
                  mib_idx = LINUX_MIB_TCPLOSSUNDO;
              else
                  mib_idx = LINUX_MIB_TCPFULLUNDO;
       
              NET_INC_STATS_BH(sock_net(sk), mib_idx);
              tp->undo_marker = 0;
          }
          if (tp->snd_una == tp->high_seq && tcp_is_reno(tp)) {
              /* Hold old state until something *above* high_seq
               * is ACKed. For Reno it is MUST to prevent false
               * fast retransmits (RFC2582). SACK TCP is safe. */
              tcp_moderate_cwnd(tp);
              return true;
         }
         //设置状态为open.
         tcp_set_ca_state(sk, TCP_CA_Open);
         return false;
    }      
	#+END_SRC
	#+html: </div>

** 拥塞事件	  
　　　TCP定义了几个拥塞事件，当这些事件发生时，我们可以通过TCP的拥塞控制算法，调用自定义的处理函数，
　　　来做一些额外的事情的。也就是说，我们可以很简便的参与到TCP对拥塞事件的处理过程中。
　　　 
*** TCP的拥塞事件集
	#+BEGIN_SRC c -n 	 
　　　 	/* Events passed to congestion control interface */  
　　　 	  
　　　 	enum tcp_ca_event {  
　　　 	    CA_EVENT_TX_START, /* first transmit when no packets in flight */  
　　　 	    CA_EVENT_CWND_RESTART, /* congestion window restart */  
　　　 	    CA_EVENT_COMPLETE_CWR, /* end of congestion recovery */  
　　　 	    CA_EVENT_FRTO, /* fast recovery timeout */  
　　　 	    CA_EVENT_LOSS, /* loss timeout */  
　　　 	    CA_EVENT_FAST_ACK, /* in sequence ack */  
　　　 	    CA_EVENT_SLOW_ACK, /* other ack */  
　　　 	 };  
	#+END_SRC
	　　　 
*** 钩子函数定义
	#+BEGIN_SRC c -n  
　　　 	 struct tcp_congestion_ops {  
　　　 	     ...  
　　　 	   
　　　 	     /* call when cwnd event occurs (optional) */  
　　　 	     void (*cwnd_event) (struct sock *sk, enum tcp_ca_event ev);  
　　　 	   
　　　 	     ...  
　　　 	 };  
	#+END_SRC　　　 
*** 封装调用
	#+BEGIN_SRC c -n  	
　　　 	static inline void tcp_ca_event (struct sock *sk, const enum tcp_ca_event event)  
　　　 	{  
　　　 	    const struct inet_connection_sock *icsk = inet_csk(sk);  
　　　 	  
　　　 	    if (icsk->icsk_ca_ops->cwnd_event)  
　　　 	        icsk->icsk_ca_ops->cwnd_event(sk, event);  
　　　 	}  
	#+END_SRC　　　 
　　　 
*** CA_EVENT_TX_START 
　　　当发送一个数据包时，如果网络中无发送且未确认的数据包，则触发此事件。
	#+BEGIN_SRC c -n  	
　　　 	static int tcp_transmit_skb(struct sock *sk, struct sk_buff *skb, int clone_it, gfp_t gfp_mask)  
　　　 	{  
　　　 	    ...  
　　　 	  
　　　 	    if (tcp_packets_in_flight(tp) == 0) {  
　　　 	        tcp_ca_event(sk, CA_EVENT_TX_START);  
　　　 	        skb->ooo_okay = 1; /*此时发送队列可以改变，因为上面没有数据包 */  
　　　 	  
　　　 	    } else  
　　　 	         skb->ooo_okay = 0;   
　　　 	     ...  
　　　 	 }  
	#+END_SRC　　　 
　　　 
*** CA_EVENT_CWND_RESTART 
　　　发送方在发送数据包时，如果发送的数据包有负载，则会检测拥塞窗口是否超时。
　　　如果超时，则会使拥塞窗口失效并重新计算拥塞窗口，同时触发CA_EVENT_CWND_RESTART事件。
	#+BEGIN_SRC c -n  	
　　　 	/* Congestion state accounting after a packet has been sent. */  　　　 	  
　　　 	static void tcp_event_data_sent(struct tcp_sock *tp, struct sock *sk)  
　　　 	{  
　　　 	    struct inet_connection_sock *icsk = inet_csk(sk);  
　　　 	    const u32 now = tcp_time_stamp;  
　　　 	      
　　　 	    if (sysctl_tcp_slow_start_after_idle &&  
　　　 	        (! tp->packets_out && (s32) (now - tp->lsndtime) > icsk->icsk_rto))  
　　　 	         tcp_cwnd_restart(sk, __sk_dst_get(sk)); /* 重置cwnd */  
　　　 	    
　　　 	     tp->lsndtime = now; /* 更新最近发包的时间*/  
　　　 	   
　　　 	     /* If it is a reply for ato after last received packet, enter pingpong mode. */  
　　　 	     if ((u32) (now - icsk->icsk_ack.lrcvtime) < icsk->icsk_ack.ato)  
　　　 	         icsk->icsk_ack.pingpong = 1;  
　　　 	 }  
	#+END_SRC　　　 
　　　 
　　　tcp_event_data_sent()中，符合三个条件才重置cwnd：
　　　（1）tcp_slow_start_after_idle选项设置，这个内核默认置为1
　　　（2）tp->packets_out == 0，表示网络中没有未确认数据包
　　　（3）now - tp->lsndtime > icsk->icsk_rto，距离上次发送数据包的时间超过了RTO
	#+BEGIN_SRC c -n  	　　　 
　　　 	/* RFC2861. Reset CWND after idle period longer than RTO to "restart window". 
　　　 	 * This is the first part of cwnd validation mechanism. 
　　　 	 */  
　　　 	static void tcp_cwnd_restart(struct sock *sk, const struct dst_entry *dst)  
　　　 	{  
　　　 	    struct tcp_sock *tp = tcp_sk(sk);  
　　　 	    s32 delta = tcp_time_stamp - tp->lsndtime; /* 距离上次发包的时间*/  
　　　 	    u32 restart_cwnd = tcp_init_cwnd(tp, dst);  
　　　 	     u32 cwnd = tp->snd_cwnd;  
　　　 	   
　　　 	     tcp_ca_event(sk, CA_EVENT_CWND_RESTART); /* 在这里！触发拥塞窗口重置事件*/  
　　　 	     tp->snd_ssthresh = tcp_current_ssthresh(sk); /* 保存阈值，并没有重置*/  
　　　 	     restart_cwnd = min(restart_cwnd, cwnd);  
　　　 	   
　　　 	     /* 闲置时间每超过一个RTO且cwnd比重置后的大时，cwnd减半。*/  
　　　 	     while((delta -= inet_csk(sk)->icsk_rto) > 0 && cwnd > restart_cwnd)  
　　　 	         cwnd >>= 1;  
　　　 	   
　　　 	     tp->snd_cwnd = max(cwnd, restart_cwnd);  
　　　 	     tp->snd_cwnd_stamp = tcp_time_stamp;  
　　　 	     tp->snd_cwnd_used = 0;  
　　　 	 }  
	#+END_SRC　　　 　　　 
*** CA_EVENT_COMPLETE_CWR 
　　　当退出CWR状态，或者退出Recovery状态时，会调用tcp_complete_cwr()来设置拥塞窗口，这个时候
　　　会触发CA_EVENT_COMPLETE_CWR来通知拥塞控制模块：“我已经停止减小拥塞窗口了！如果你想
　　　再做点什么补充，就是现在！”
	#+BEGIN_SRC c -n  	　　　 
　　　	static inline void tcp_complete_cwr(struct sock *sk)  
　　　	{
　　　	   struct tcp_sock *tp = tcp_sk(sk);  
　　　	 
　　　	   /* Do not moderate cwnd if it's already undone in cwr or recovery. */  
　　　	   if (tp->undo_marker) {  
　　　	       if (inet_csk(sk)->icsk_ca_state == TCP_CA_CWR)  
　　　	           tp->snd_cwnd = min(tp->snd_cwnd, tp->snd_ssthresh);  
　　　	       else /* PRR */  
　　　	            tp->snd_cwnd = tp->snd_ssthresh;  
　　　	  
　　　	        tp->snd_cwnd_stamp = tcp_time_stamp;  
　　　	    }  
　　　	   
　　　	    /* 在这里设置拥塞窗口和慢启动阈值会覆盖掉ssthresh()的设置*/  
　　　	    tcp_ca_event(sk, CA_EVENT_COMPLETE_CWR);  
　　　	}  
	#+END_SRC　　　 
*** CA_EVENT_FRTO 
　　　启用F-RTO时，发生超时后，首先会进行F-RTO处理，看看这个超时是不是虚假的，如果不是的话
　　　再进行传统的超时重传。这时候会减小慢启动阈值，而拥塞窗口暂时保持不变。
	#+BEGIN_SRC c -n  	　　　 
　　　/* RTO occurred, but do not yet enter Loss state. Instead, defer RTO recovery a bit and use 
　　　 * heuristics in tcp_process_frto() to detect if the RTO was spurious. 
　　　 */  
　　　void tcp_enter_frto(struct sock *sk)  
　　　{  
　　　    const struct inet_connection_sock *icsk = inet_csk(sk);  
　　　    struct tcp_sock *tp = tcp_sk(sk);  
　　　    struct sk_buff *skb;  
　　　    
　　　     if ((! tp->frto_counter && icsk->icsk_ca_state <= TCP_CA_Disorder) ||  
　　　         tp->snd_una == tp->high_seq ||  
　　　         ((icsk->icsk_ca_state == TCP_CA_Loss || tp->frto_counter) &&  
　　　          ! icsk->icsk_retransmits)) {  
　　　   
　　　         tp->prior_ssthresh = tcp_current_ssthresh(sk); /* 保留旧阈值*/  
　　　   
　　　         if (tp->frto_counter) { /* 这种情况非常罕见*/  
　　　             u32 stored_cwnd;  
　　　             stored_cwnd = tp->snd_cwnd;  
　　　             tp->snd_cwnd = 2;  
　　　             tp->snd_ssthresh = icsk->icsk_ca_ops->ssthresh(sk);  
　　　             tp->snd_cwnd = stored_cwnd;  
　　　   
　　　         } else {  
　　　             tp->snd_ssthresh = icsk->icsk_ca_ops->ssthresh(sk); /* 重新设置慢启动阈值*/  
　　　         }  
　　　   
　　　         tcp_ca_event(sk, CA_EVENT_FRTO); /* 这里设置慢启动阈值会覆盖掉ssthresh()的设置*/  
　　　     }  
　　　     ...  
　　　 }  
	#+END_SRC　　　 
*** CA_EVENT_LOSS 
　　　上面我们说到，如果超时不是虚假的话，就会进入超时重传，也就是TCP_CA_Loss状态。
	#+BEGIN_SRC c -n  	　　　 
　　　/* Enter Loss state. If "how" is not zero, forget all SACK information and reset tags completely, 
　　　 * otherwise preserve SACKs. If receiver dropped its ofo queue, we will know this due to 
　　　 * reneging detection. 
　　　 */  
　　　void tcp_enter_loss(struct sock *sk, int how)  
　　　{  
　　　    const struct inet_connection_sock *icsk = inet_csk(sk);  
　　　    struct tcp_sock *tp = tcp_sk(sk);  
　　　     struct sk_buff *skb;  
　　　    
　　　     /* Reduce ssthresh if it has not yet been made inside this window. 
　　　      * 要么是从Open或Disorder状态进入Loss状态，要么是在Loss状态又发生了超时：） 
　　　      * 我们知道在CWR或Recovery状态中可以以进入Loss，但在那两个状态中阈值已经被重置过了。 
　　　      */  
　　　     if (icsk->icsk_ca_state <= TCP_CA_Disorder || tp->snd_una == tp->high_seq ||  
　　　         (icsk->icsk_ca_state == TCP_CA_Loss && ! icsk->icsk_retransmits)) {  
　　　   
　　　         tp->prior_ssthresh = tcp_current_ssthresh(sk); /* 保存旧阈值*/  
　　　         tp->snd_ssthresh = icsk->icsk_ca_ops->ssthresh(sk); /* 重新设置慢启动阈值*/  
　　　   
　　　         tcp_ca_event(sk, CA_EVENT_LOSS); /* 这里设置慢启动阈值会覆盖掉ssthresh()的设置*/  
　　　     }  
　　　   
　　　     tp->snd_cwnd = 1;  
　　　     tp->snd_cwnd_cnt = 0;  
　　　     tp->snd_cwnd_stamp = tcp_time_stamp;  
　　　     ...  
　　　 }   
	#+END_SRC　　　 
　　　 
*** CA_EVENT_FAST_ACK 	
　　　如果我们收到符合预期的ACK，那么就进入快速路径的处理流程，在tcp_ack()中进行负荷无关的处理，
　　　同时触发CA_EVENT_FAST_ACK事件。
	#+BEGIN_SRC c -n  	　　　 
　　　static int tcp_ack(struct sock *sk, const struct sk_buff *skb, int flag)  
　　　{  
　　　    ...  
　　　    /* 如果处于快速路径中*/  
　　　    if (! (flag & FLAG_SLOWPATH) && after(ack, prior_snd_una)) {  
　　　  
　　　        /* Window is constant, pure forward advance. 
　　　         * No more checks are required. 
　　　         */  
　　　         tcp_update_w1(tp, ack_seq); /*记录更新发送窗口的ACK段序号*/  
　　　         tp->snd_una = ack; /* 更新发送窗口左端 */  
　　　         flag |= FLAG_WIN_UPDATE; /* 设置发送窗口更新标志 */  
　　　   
　　　         tcp_ca_event(sk, CA_EVENT_FAST_ACK); /* 快速路径拥塞事件钩子*/  
　　　   
　　　         NET_INC_STATS_BH(sock_net(sk), LINUX_MIB_TCPHPACKS);  
　　　     }  
　　　    ...  
　　　 }  
	#+END_SRC　　　 
　　　 
*** CA_EVENT_SLOW_ACK	
　　　如果我们收到不符合预期的ACK，那么就不能走快速路径，而必须经过全面的检查，即进入慢速路径的
　　　处理流程。同样在tcp_ack()中进行负荷无关的处理，同时触发CA_EVENT_SLOW_ACK事件。
	#+BEGIN_SRC c -n  	　　　 
　　　static int tcp_ack(struct sock *sk, const struct sk_buff *skb, int flag)  
　　　{  
　　　    ...  
　　　    /* 如果处于快速路径中*/  
　　　    if (! (flag & FLAG_SLOWPATH) && after(ack, prior_snd_una)) {  
　　　        ...  
　　　  
　　　    } else { /* 进入慢速路径 */  
　　　        if (ack_seq != TCP_SKB_CB(skb)->end_seq)  
　　　             flag |= FLAG_DATA; /* 此ACK携带负荷*/  
　　　         else  
　　　             NET_INC_STATS_BH(sock_net(sk), LINUX_MIB_TCPPUREACKS);  
　　　   
　　　         flag |= tcp_ack_update_window(sk, skb, ack, ack_seq); /* 更新发送窗口*/  
　　　           
　　　          /* 根据SACK选项标志重传队列中SKB的记分牌状态*/  
　　　         if (TCP_SKB_CB(skb)->sacked)  
　　　             flag |= tcp_sacktag_write_queue(sk, skb, prior_snd_una);  
　　　    
　　　         /* 查看ACK是否携带ECE标志 */  
　　　         if (TCP_ECN_rcv_ecn_echo(tp, tcp_hdr(skb)))  
　　　             flag |= FLAG_ECE;  
　　　    
　　　         tcp_ca_event(sk, CA_EVENT_SLOW_ACK); /* 慢速路径拥塞事件钩子*/  
　　　     }  
　　　     ...  
　　　 }  
	#+END_SRC　　　 
　　　 
*** 阈值的设置 
　　　用拥塞算法的ssthresh()来设置慢启动阈值tp->snd_ssthresh。
　　　（1）tcp_enter_cwr
　　　    进入CWR状态时。
　　　    Set slow start threshold and cwnd not falling to slow start.
　　　（2）tcp_enter_frto
　　　    进入FRTO处理时。
　　　（3）tcp_enter_loss
　　　     进入Loss状态时。
　　　（4）tcp_fastretrans_alert
　　　    进入Recovery状态时。
　　　可见ssthresh()的调用时机是在进入CWR、FRTO、Loss、Recovery这几个异常状态时。
　　　 
　　　tp->snd_ssthresh的使用：
　　　（1）在进入CWR、FRTO、Loss、Recovery时调用ssthresh()重新设置，在退出这些状态时，作为慢启动阈值。
　　　（2）作为tcp_cwnd_min()的返回值，在tcp_cwnd_down()中被调用，而tcp_cwnd_down()在CWR和Recovery
　　　    状态中被调用。
　　　（3）退出CWR、Recovery状态时，赋值给tp->snd_cwnd，避免进入慢启动。
	  	
* 第30章 TCP的输出
** tcp_sendmsg()
   1. 先计算应该copy的序号与位置，设置skb->end_seq.
      TCP_SKB_CB(skb)->end_seq += copy;
   2. 通过调用__tcp_push_pending_frames()发送队列的段。
	  __tcp_push_pending_frames(sk, mss_now, TCP_NAGLE_PUSH);
	  
*** tcp_write_xmit()
   1. 使用tcp_cwnd_test()检查拥塞窗口是否还有空间。
   2. 使用tcp_snd_wnd_test()检查滑动窗口是否还有空间。
   3. 使用tcp_transmit_skb()发送当前skb.
   4. 使用tcp_event_new_data_sent()递增packets_out.

	  
